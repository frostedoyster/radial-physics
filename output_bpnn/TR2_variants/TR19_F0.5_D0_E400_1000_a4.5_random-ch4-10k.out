STARTING AT Sun Dec 11 17:21:36 CET 2022
CUDA is available:  False
Random seed: 1000
6 14
Reading dataset
Shuffling and extracting from dataset (length: 10000)
Shuffling and extraction done
Calculating composition features
Composition features done
Calculating composition features
Composition features done
Creating datasets and dataloaders
0
100
200
300
400
500
Epoch 00170: reducing learning rate of group 0 to 1.0000e-06.
600
700
800
900
0
100
200
300
400
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
500
600
700
800
900
nfeat: 218
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 3.349726573688794 [MAE: 2.535011688232422]
Test error minimum for model run no. 1:  11.477233487846533 [MAE: 6.325830142974853]
Epoch 00353: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00150: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00276: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00111: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00112: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00231: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00074: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 3.9082368888559413 [MAE: 2.9745344524383546]
Test error minimum for model run no. 1:  11.713660878204823 [MAE: 6.4920778007507325]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 4.291049148254989 [MAE: 3.2997508430480957]
Test error minimum for model run no. 2:  11.575150334347988 [MAE: 6.485528972625732]
Epoch 00335: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00333: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00173: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00076: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00056: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00104: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00096: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 3.845827225542161 [MAE: 2.944168394088745]
Test error minimum for model run no. 2:  11.89080975639381 [MAE: 6.558458896636963]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 3.888419313192814 [MAE: 2.9757855434417726]
Test error minimum for model run no. 3:  11.848728639028245 [MAE: 6.578275001525879]
Epoch 00359: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00275: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00233: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00278: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00067: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00147: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 3.5075328689960132 [MAE: 2.661003065109253]
Test error minimum for model run no. 3:  11.761543855631812 [MAE: 6.409454006195069]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 3.943841974361776 [MAE: 3.0333580989837645]
Test error minimum for model run no. 4:  11.738851130743203 [MAE: 6.5233580627441405]
Epoch 00294: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00369: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00286: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00087: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00143: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00140: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 3.850483466173931 [MAE: 2.9289757671356202]
Test error minimum for model run no. 5:  11.794146584219433 [MAE: 6.507795623779296]
Epoch 00097: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 3.771604869180057 [MAE: 2.861092514038086]
Test error minimum for model run no. 4:  11.488574303669923 [MAE: 6.422831077575683]
Epoch 00357: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00093: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00228: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00109: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00082: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00194: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00438: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00104: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 3.7775408867694074 [MAE: 2.8615747203826905]
Test error minimum for model run no. 6:  11.383516496513083 [MAE: 6.344899280548096]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 4.058218519765625 [MAE: 3.122883800506592]
Test error minimum for model run no. 5:  11.52674001802397 [MAE: 6.425122417449951]
Epoch 00341: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00073: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00067: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00308: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00136: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00059: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 3.9713702506451534 [MAE: 3.0323447456359864]
Test error minimum for model run no. 7:  11.823788035184688 [MAE: 6.5338279914855955]
Epoch 00058: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 3.99199069941131 [MAE: 3.050924549102783]
Test error minimum for model run no. 6:  11.439266193870555 [MAE: 6.336474800109864]
Epoch 00398: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00086: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00250: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00056: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00063: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00189: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00061: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 3.656312565977354 [MAE: 2.7632453346252444]
Test error minimum for model run no. 8:  11.302634673722183 [MAE: 6.325886589050293]
Epoch 00091: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00234: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 3.807742090775648 [MAE: 2.9090331573486328]
Test error minimum for model run no. 7:  12.124557992016452 [MAE: 6.38969616317749]
Epoch 00186: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00063: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00360: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00060: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 4.50136868918652 [MAE: 3.46484397315979]
Test error minimum for model run no. 9:  12.406609237889185 [MAE: 6.738590230941773]
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00122: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00315: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 3.8180305260206775 [MAE: 2.905269474029541]
Test error minimum for model run no. 8:  11.728845231760076 [MAE: 6.6079987640380855]
Epoch 00185: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00078: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00097: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00248: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00107: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 3.9697668293429786 [MAE: 3.0318074951171874]
Test error minimum for model run no. 10:  12.167396474679615 [MAE: 6.626936302185059]
E_max_2 =  400
Cutoff Radius =  4.5
Selected Radial Transform =  19.0
factor =  0.5
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  1000
n_test =  1000
Train error averaged over all models Train RMSE:  3.9199879697593722 [Train MAE: 2.992669820976258]
Test error averaged over all models Test RMSE: 11.751805509417416 [Test MAE: 6.499092819786073]
FINISHED at Sun Dec 11 20:57:53 CET 2022
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00212: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 4.398393343498865 [MAE: 3.363447727203369]
Test error minimum for model run no. 9:  11.88889123102167 [MAE: 6.520262020111084]
Epoch 00318: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00188: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00079: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00096: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 3.8791596813255103 [MAE: 2.9535403480529787]
Test error minimum for model run no. 10:  11.758225055541189 [MAE: 6.475548896789551]
E_max_2 =  400
Cutoff Radius =  4.5
Selected Radial Transform =  19.0
factor =  0.5
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  1000
n_test =  1000
Train error averaged over all models Train RMSE:  3.898673671337181 [Train MAE: 2.9745897481918337]
Test error averaged over all models Test RMSE: 11.732111451613429 [Test MAE: 6.463792484283447]
FINISHED at Sun Dec 11 21:36:32 CET 2022
