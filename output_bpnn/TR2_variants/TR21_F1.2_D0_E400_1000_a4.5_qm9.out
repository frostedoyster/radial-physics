STARTING AT Sat Dec 17 02:25:50 CET 2022
CUDA is available:  False
Random seed: 1000
6 14
Reading dataset
Shuffling and extracting from dataset (length: 10000)
Shuffling and extraction done
Calculating composition features
Composition features done
Calculating composition features
Composition features done
Creating datasets and dataloaders
0
100
200
300
400
500
Epoch 00072: reducing learning rate of group 0 to 1.0000e-06.
600
700
800
900
0
100
200
300
400
500
600
700
800
900
nfeat: 218
Epoch 00092: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 5.055667599192632 [MAE: 3.922374622732529]
Test error minimum for model run no. 6:  11.172472565882845 [MAE: 6.677497494000314]
Epoch 00595: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00056: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00504: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00072: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00069: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00087: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 4.784472305391805 [MAE: 3.7179023772483997]
Test error minimum for model run no. 1:  11.8992241942403 [MAE: 6.538442585520249]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 4.875145100191869 [MAE: 3.7209663504388204]
Test error minimum for model run no. 7:  12.004754968695128 [MAE: 6.781540145447909]
Epoch 00370: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00377: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00260: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00131: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00293: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 5.564942892281997 [MAE: 4.264913792225218]
Test error minimum for model run no. 2:  12.696970791310187 [MAE: 6.92431134938239]
Epoch 00255: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 5.140718785788866 [MAE: 3.836906661530233]
Test error minimum for model run no. 8:  11.963940968301197 [MAE: 6.631348869716038]
Epoch 00473: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00106: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00097: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00391: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00142: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00182: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00059: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 5.208422235585767 [MAE: 3.9956645280597605]
Test error minimum for model run no. 3:  12.028331022219133 [MAE: 6.914735654369753]
Epoch 00135: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 5.446641959966883 [MAE: 4.229676976225567]
Test error minimum for model run no. 9:  12.62684225223115 [MAE: 6.921909029447746]
Epoch 00488: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00109: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00368: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00113: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00110: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 4.88143425994431 [MAE: 3.7081888119483954]
Test error minimum for model run no. 4:  11.638570692563459 [MAE: 6.637840249246936]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 5.469043911236828 [MAE: 4.143669876781127]
Test error minimum for model run no. 10:  12.328698252074917 [MAE: 6.842319902220905]
E_max_2 =  400
Cutoff Radius =  4.5
Selected Radial Transform =  21.0
factor =  1.2
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  1000
n_test =  1000
Train error averaged over all models Train RMSE:  5.041302705135694 [Train MAE: 3.8735934372433425]
Test error averaged over all models Test RMSE: 11.914514979631479 [Test MAE: 6.714433619788774]
FINISHED at Sat Dec 17 04:22:09 CET 2022
Epoch 00466: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00507: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00065: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00066: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 4.848664987447971 [MAE: 3.751937097330326]
Test error minimum for model run no. 5:  12.044513601667479 [MAE: 6.778824815817128]
Epoch 00487: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00079: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00092: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00064: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00067: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 5.170992229994351 [MAE: 3.9815023775954588]
Test error minimum for model run no. 6:  12.095227090513527 [MAE: 6.9896306041981955]
Epoch 00425: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00145: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00096: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 5.14862765493714 [MAE: 3.84326633233661]
Test error minimum for model run no. 7:  12.285359409338026 [MAE: 6.754650772585323]
Epoch 00533: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00130: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00085: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 4.9015824377354855 [MAE: 3.8325484360741964]
Test error minimum for model run no. 8:  12.626006307584678 [MAE: 6.961686686113342]
Epoch 00392: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00417: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00376: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00085: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 5.052605379716905 [MAE: 3.7600776028871175]
Test error minimum for model run no. 9:  12.007947379442719 [MAE: 6.674294668519196]
Epoch 00410: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00062: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00081: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00112: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 5.28578578267071 [MAE: 3.969846086543458]
Test error minimum for model run no. 10:  12.427578029449384 [MAE: 6.931594290096033]
E_max_2 =  400
Cutoff Radius =  4.5
Selected Radial Transform =  21.0
factor =  1.2
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  1000
n_test =  1000
Train error averaged over all models Train RMSE:  5.084753016570644 [Train MAE: 3.8825847442248937]
Test error averaged over all models Test RMSE: 12.174972851832889 [Test MAE: 6.810601167584854]
FINISHED at Sat Dec 17 07:11:53 CET 2022
