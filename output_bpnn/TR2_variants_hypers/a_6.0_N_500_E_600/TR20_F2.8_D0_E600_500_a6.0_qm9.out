STARTING AT Sat Dec 24 00:10:13 CET 2022
CUDA is available:  False
Random seed: 1000
7 18
Reading dataset
Shuffling and extracting from dataset (length: 10000)
Shuffling and extraction done
Calculating composition features
Composition features done
Calculating composition features
Composition features done
Creating datasets and dataloaders
0
100
200
Epoch 00086: reducing learning rate of group 0 to 1.0000e-06.
300
400
0
100
200
300
400
nfeat: 406
Epoch 00220: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00133: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 10.268463431584696 [MAE: 7.365355671088489]
Test error minimum for model run no. 1:  14.103461729916381 [MAE: 9.475786263052575]
Epoch 00800: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00194: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00783: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 9.677067454885426 [MAE: 7.242356364553704]
Test error minimum for model run no. 1:  13.514131931620978 [MAE: 9.442244906321461]
Epoch 00211: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00063: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 9.778291343863176 [MAE: 7.283126468742518]
Test error minimum for model run no. 2:  13.46079016297351 [MAE: 9.454314158569979]
Epoch 00780: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00089: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00667: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00228: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00133: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 9.703196813527656 [MAE: 7.226156385441194]
Test error minimum for model run no. 2:  13.783500243315252 [MAE: 9.396638597810359]
Epoch 00365: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00171: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 9.96259524772656 [MAE: 7.288391513618287]
Test error minimum for model run no. 3:  13.946330730852402 [MAE: 9.517906271425536]
Epoch 00721: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00116: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00066: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00079: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 9.687283294707768 [MAE: 7.244492555560727]
Test error minimum for model run no. 3:  13.645214275952693 [MAE: 9.415223786699235]
Epoch 00827: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00123: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00102: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 9.74662851421467 [MAE: 7.28008982556896]
Test error minimum for model run no. 4:  13.54794477232083 [MAE: 9.467607423185216]
Epoch 00769: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00060: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00185: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00158: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00598: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 9.579714318327776 [MAE: 7.22632358092891]
Test error minimum for model run no. 4:  13.506967893890824 [MAE: 9.352301284347307]
Epoch 00186: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00093: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00146: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 10.396868987922332 [MAE: 7.4754927813752055]
Test error minimum for model run no. 5:  14.035269259919415 [MAE: 9.560980500013157]
Epoch 00686: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00099: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00152: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00068: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00636: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 10.042776383415278 [MAE: 7.394204915316263]
Test error minimum for model run no. 5:  13.863522712097508 [MAE: 9.528755619722505]
Epoch 00139: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00123: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 10.159853309253153 [MAE: 7.395568694877163]
Test error minimum for model run no. 6:  13.927346099208025 [MAE: 9.43419215838102]
Epoch 00745: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00191: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00056: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00709: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 10.013471704726191 [MAE: 7.385827697527536]
Test error minimum for model run no. 6:  13.678343498165644 [MAE: 9.402985666169867]
Epoch 00156: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00068: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00153: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 9.874443828566177 [MAE: 7.334040118149066]
Test error minimum for model run no. 7:  13.701684350509005 [MAE: 9.528947136114247]
Epoch 00740: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00101: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00132: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00066: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 9.908800144988954 [MAE: 7.313984274900977]
Test error minimum for model run no. 7:  13.846326245897634 [MAE: 9.48751671133526]
Epoch 00773: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00100: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00114: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00094: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00072: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00720: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 9.703496879847803 [MAE: 7.21152913787097]
Test error minimum for model run no. 8:  13.819813863507822 [MAE: 9.405143400130891]
Epoch 00188: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00127: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00074: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 9.735117130779843 [MAE: 7.255270559642801]
Test error minimum for model run no. 8:  13.560623699289149 [MAE: 9.434750252022859]
Epoch 00787: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00077: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00069: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00100: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 9.857888025595615 [MAE: 7.338868255838523]
Test error minimum for model run no. 9:  13.637876420608954 [MAE: 9.589654038574512]
Epoch 00799: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00158: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00056: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00071: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 9.452957017073988 [MAE: 7.149974493053048]
Test error minimum for model run no. 9:  13.431759912034373 [MAE: 9.397765428811528]
Epoch 00634: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00282: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00085: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00199: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00759: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00150: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 10.214953068060542 [MAE: 7.402133689792388]
Test error minimum for model run no. 10:  13.842840401255488 [MAE: 9.447077375466435]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  2.8
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  500
n_test =  500
Train error averaged over all models Train RMSE:  9.996348263663473 [Train MAE: 7.337459615692157]
Test error averaged over all models Test RMSE: 13.802335779107185 [Test MAE: 9.488160872491356]
FINISHED at Sat Dec 24 03:04:28 CET 2022
Epoch 00114: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00159: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 9.572669558376054 [MAE: 7.1562163762679285]
Test error minimum for model run no. 10:  13.81203989921543 [MAE: 9.503971522486642]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  2.8
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  500
n_test =  500
Train error averaged over all models Train RMSE:  9.737305382080894 [Train MAE: 7.25948072031931]
Test error averaged over all models Test RMSE: 13.664243031147947 [Test MAE: 9.436215377572701]
FINISHED at Sat Dec 24 03:11:24 CET 2022
