STARTING AT Sat Dec 24 00:10:13 CET 2022
CUDA is available:  False
Random seed: 1000
7 18
Reading dataset
Shuffling and extracting from dataset (length: 10000)
Shuffling and extraction done
Calculating composition features
Composition features done
Calculating composition features
Composition features done
Creating datasets and dataloaders
0
Epoch 00094: reducing learning rate of group 0 to 1.0000e-06.
100
200
300
400
0
100
200
300
Epoch 00120: reducing learning rate of group 0 to 1.0000e-07.
400
nfeat: 406
Epoch 00099: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 10.778320589022355 [MAE: 7.6904976221758234]
Test error minimum for model run no. 1:  14.891150814978552 [MAE: 10.058409918433298]
Epoch 00647: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00708: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00440: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00068: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00239: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00099: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00088: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00077: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 10.28489805482878 [MAE: 7.480919611125477]
Test error minimum for model run no. 1:  14.34939712878521 [MAE: 9.623460673293955]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 10.144893917575613 [MAE: 7.44937247477952]
Test error minimum for model run no. 2:  14.191888144452822 [MAE: 9.620625315953777]
Epoch 00639: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00648: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00071: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00167: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00116: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 10.568386647998336 [MAE: 7.608738672641419]
Test error minimum for model run no. 2:  14.219004997537683 [MAE: 9.766722083830166]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 10.452516624781342 [MAE: 7.5696490861628245]
Test error minimum for model run no. 3:  14.328139589626492 [MAE: 9.690606362772902]
Epoch 00647: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00080: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00086: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00635: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00067: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00115: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 10.566845730123118 [MAE: 7.68513404859133]
Test error minimum for model run no. 3:  14.343760392481572 [MAE: 9.737325253002203]
Epoch 00448: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00184: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00060: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00142: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 10.309787410063114 [MAE: 7.477480784461395]
Test error minimum for model run no. 4:  13.568468191669373 [MAE: 9.333272683814227]
Epoch 00649: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00157: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00109: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00070: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 10.543710001313489 [MAE: 7.564669557725114]
Test error minimum for model run no. 4:  14.045803906405386 [MAE: 9.577898726384621]
Epoch 00642: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00096: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00083: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 10.490008270369305 [MAE: 7.577666912367561]
Test error minimum for model run no. 5:  14.058852951326928 [MAE: 9.611061087165288]
Epoch 00634: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00143: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00075: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00142: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00077: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00670: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00062: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 10.481447882372066 [MAE: 7.551784175011671]
Test error minimum for model run no. 5:  14.319079066175513 [MAE: 9.680673425064573]
Epoch 00108: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00058: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 10.421797869688755 [MAE: 7.586937478328955]
Test error minimum for model run no. 6:  14.276071141059298 [MAE: 9.74741088323838]
Epoch 00684: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00650: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00348: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00075: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00102: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00160: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00095: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 10.195448063868753 [MAE: 7.436513755230287]
Test error minimum for model run no. 6:  13.497366524137089 [MAE: 9.303116723958974]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 10.517141825502184 [MAE: 7.663832608495023]
Test error minimum for model run no. 7:  14.349386979434914 [MAE: 9.791238863559917]
Epoch 00647: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00653: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00114: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00152: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00124: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00108: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00125: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 10.518926968985285 [MAE: 7.61751724794139]
Test error minimum for model run no. 8:  14.172882445810787 [MAE: 9.767961341965075]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 10.55079893688328 [MAE: 7.604491785509084]
Test error minimum for model run no. 7:  14.231390275511494 [MAE: 9.724145505125069]
Epoch 00665: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00639: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00106: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00062: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00082: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00208: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 10.371143581431152 [MAE: 7.523899288551429]
Test error minimum for model run no. 9:  14.29225070120826 [MAE: 9.692693694099676]
Epoch 00127: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 10.456274915963556 [MAE: 7.572472719967696]
Test error minimum for model run no. 8:  14.304426974041741 [MAE: 9.680636889528229]
Epoch 00647: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00113: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00129: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00657: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00060: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00082: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00100: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 10.489818655892662 [MAE: 7.608896815072055]
Test error minimum for model run no. 10:  14.374203644047267 [MAE: 9.73489882031793]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  3.0
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  500
n_test =  500
Train error averaged over all models Train RMSE:  10.449435571331177 [Train MAE: 7.576575031833597]
Test error averaged over all models Test RMSE: 14.250329460361467 [Test MAE: 9.704817897132049]
FINISHED at Sat Dec 24 02:46:27 CET 2022
Epoch 00205: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 10.507667320399882 [MAE: 7.583243263093033]
Test error minimum for model run no. 9:  14.29284701045735 [MAE: 9.742087961591407]
Epoch 00691: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00073: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00109: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00062: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00127: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 10.377570871320636 [MAE: 7.549107956133596]
Test error minimum for model run no. 10:  14.037626120282058 [MAE: 9.70269196236771]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  3.0
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  500
n_test =  500
Train error averaged over all models Train RMSE:  10.45330484250719 [Train MAE: 7.563707554502871]
Test error averaged over all models Test RMSE: 14.16407023958151 [Test MAE: 9.653875920414691]
FINISHED at Sat Dec 24 03:08:55 CET 2022
