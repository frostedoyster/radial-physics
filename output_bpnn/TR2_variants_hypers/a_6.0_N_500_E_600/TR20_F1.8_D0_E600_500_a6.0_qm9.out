STARTING AT Sat Dec 24 00:05:13 CET 2022
CUDA is available:  False
Random seed: 1000
7 18
Reading dataset
Shuffling and extracting from dataset (length: 10000)
Shuffling and extraction done
Calculating composition features
Composition features done
Calculating composition features
Composition features done
Creating datasets and dataloaders
0
100
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
200
300
400
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
0
100
200
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
300
400
nfeat: 406
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 9.289250180982812 [MAE: 5.60569473582176]
Test error minimum for model run no. 6:  17.139333927705973 [MAE: 9.464049182026917]
Epoch 00429: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00465: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00113: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00094: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00070: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00059: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00063: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00065: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00071: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 9.017757599241914 [MAE: 5.559427052002095]
Test error minimum for model run no. 1:  17.481493207068457 [MAE: 9.484950812316095]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 8.469530097792829 [MAE: 5.448504528271283]
Test error minimum for model run no. 7:  16.324518328566178 [MAE: 9.33906053637858]
Epoch 00517: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00577: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00074: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00123: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00061: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00090: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00169: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 7.914706242513945 [MAE: 5.291271557986748]
Test error minimum for model run no. 8:  16.573409777893705 [MAE: 9.121973926052195]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 7.21271642419216 [MAE: 5.1078515295792615]
Test error minimum for model run no. 2:  16.234016838940956 [MAE: 9.239894575137386]
Epoch 00577: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00461: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00103: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00080: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00099: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00081: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00080: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 8.677156323568752 [MAE: 5.47274825926702]
Test error minimum for model run no. 3:  18.2167503344159 [MAE: 10.138224394766146]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 7.414220486275165 [MAE: 5.122195439788864]
Test error minimum for model run no. 9:  16.624390460274775 [MAE: 8.984902530255662]
Epoch 00376: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00061: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00072: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00627: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 9.670868475921008 [MAE: 5.840547780318584]
Test error minimum for model run no. 4:  18.232537469662798 [MAE: 9.999976348856034]
Epoch 00155: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00082: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00075: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00365: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 6.8882880534366535 [MAE: 5.016299571829514]
Test error minimum for model run no. 10:  15.974742674427056 [MAE: 9.016343922318951]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  1.8
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  500
n_test =  500
Train error averaged over all models Train RMSE:  8.123971962446365 [Train MAE: 5.302971053746999]
Test error averaged over all models Test RMSE: 16.715505320839153 [Test MAE: 9.23203119052236]
FINISHED at Sat Dec 24 01:06:07 CET 2022
Epoch 00148: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00060: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00162: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 9.88600964136228 [MAE: 5.83005896442632]
Test error minimum for model run no. 5:  18.226327596005543 [MAE: 9.934126895244507]
Epoch 00975: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00084: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00085: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 5.720374838092838 [MAE: 4.469771556020178]
Test error minimum for model run no. 6:  15.045327127723604 [MAE: 8.835486884857485]
Epoch 00440: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00056: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00288: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00094: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00084: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 8.788356371361582 [MAE: 5.545042353308499]
Test error minimum for model run no. 7:  17.19351279764174 [MAE: 9.654085161618523]
Epoch 00474: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00112: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00085: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 8.369482006687448 [MAE: 5.426430749737731]
Test error minimum for model run no. 8:  17.13047109753227 [MAE: 9.32156433649173]
Epoch 00376: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00082: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 9.794401064716734 [MAE: 5.808708981691767]
Test error minimum for model run no. 9:  18.288465135477853 [MAE: 9.74947604030058]
Epoch 00438: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00314: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00079: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00075: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 8.340986120588722 [MAE: 5.37540596174082]
Test error minimum for model run no. 10:  17.409906535538013 [MAE: 9.41312117935816]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  1.8
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  500
n_test =  500
Train error averaged over all models Train RMSE:  8.547810886573345 [Train MAE: 5.443599318809228]
Test error averaged over all models Test RMSE: 17.345880814000715 [Test MAE: 9.577090662894665]
FINISHED at Sat Dec 24 02:28:28 CET 2022
