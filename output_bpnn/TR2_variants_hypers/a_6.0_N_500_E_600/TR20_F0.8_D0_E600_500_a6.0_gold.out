STARTING AT Mon Dec 19 00:52:28 CET 2022
CUDA is available:  False
Random seed: 1000
7 18
Reading dataset
Shuffling and extracting from dataset (length: 10000)
Shuffling and extraction done
Calculating composition features
Composition features done
Calculating composition features
Composition features done
Creating datasets and dataloaders
0
100
200
300
400
0
100
Epoch 00188: reducing learning rate of group 0 to 1.0000e-07.
200
300
400
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
nfeat: 406
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 3.0346768084388573 [MAE: 2.2872557822130535]
Test error minimum for model run no. 1:  13.923409650031196 [MAE: 7.986235094081303]
Epoch 00556: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00673: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00075: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 3.841324453373688 [MAE: 2.7395501781079656]
Test error minimum for model run no. 1:  15.398231344904152 [MAE: 8.574537855246486]
Epoch 00063: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 3.111821089891562 [MAE: 2.3565708933453453]
Test error minimum for model run no. 2:  14.189349417957988 [MAE: 8.233086359360364]
Epoch 00476: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00067: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00099: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00152: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00701: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 4.483575695089221 [MAE: 2.897010193624446]
Test error minimum for model run no. 2:  15.733505807386798 [MAE: 8.68037311324217]
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00072: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 3.0302514680120316 [MAE: 2.2873025956917115]
Test error minimum for model run no. 3:  14.346902233987782 [MAE: 8.084718795075242]
Epoch 00652: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00064: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00094: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00063: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00789: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 3.2924472495512638 [MAE: 2.4398138333792714]
Test error minimum for model run no. 3:  14.268172786229764 [MAE: 8.071673167966768]
Epoch 00055: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00090: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00077: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 2.729787499225592 [MAE: 2.033106695094293]
Test error minimum for model run no. 4:  14.12031801912001 [MAE: 8.118561472782982]
Epoch 00751: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00128: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00074: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00085: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00562: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00061: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00056: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 2.813888616576291 [MAE: 2.087863040620291]
Test error minimum for model run no. 4:  13.893498456644146 [MAE: 7.882600484896277]
Epoch 00083: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 3.7617682170543265 [MAE: 2.6796694109765062]
Test error minimum for model run no. 5:  14.727588708344925 [MAE: 8.354380206497728]
Epoch 00684: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00082: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00056: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00128: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00068: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00743: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00080: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00064: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 2.9838095917125558 [MAE: 2.2663034766930754]
Test error minimum for model run no. 5:  13.566286804487225 [MAE: 7.727851927945488]
Epoch 00076: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 2.975411181137219 [MAE: 2.2586757371941353]
Test error minimum for model run no. 6:  13.764110456733528 [MAE: 7.98382802612463]
Epoch 00598: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00064: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00079: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00651: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00071: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00080: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 4.036439434267469 [MAE: 2.689172024152088]
Test error minimum for model run no. 6:  18.017918500588134 [MAE: 9.489961584470157]
Epoch 00079: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00101: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 3.00851944706231 [MAE: 2.222605702528771]
Test error minimum for model run no. 7:  13.979202510331326 [MAE: 7.83693671381577]
Epoch 00566: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00080: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00129: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00104: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00660: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00059: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00061: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 3.6150661393986048 [MAE: 2.6406236068459243]
Test error minimum for model run no. 7:  14.381686688070594 [MAE: 8.341704520959377]
Epoch 00071: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00063: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 3.1544706808450926 [MAE: 2.349963858196312]
Test error minimum for model run no. 8:  14.417527018507828 [MAE: 8.008596527022924]
Epoch 00530: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00083: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00091: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00592: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 4.7470581321138585 [MAE: 2.9581842417203448]
Test error minimum for model run no. 8:  17.57809582708024 [MAE: 9.556428015615642]
Epoch 00201: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00101: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00059: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 3.650271556888392 [MAE: 2.6503908404115775]
Test error minimum for model run no. 9:  14.382921344248128 [MAE: 8.171520314143212]
Epoch 00606: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00097: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00101: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00137: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 3.385199970732178 [MAE: 2.5100336035266224]
Test error minimum for model run no. 9:  14.041848556813859 [MAE: 7.943689145062083]
Epoch 00727: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00058: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00056: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00077: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 3.0070727331485445 [MAE: 2.2437180197043505]
Test error minimum for model run no. 10:  13.633079075523515 [MAE: 7.914409294617557]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  0.8
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  500
n_test =  500
Train error averaged over all models Train RMSE:  3.1464050681703926 [Train MAE: 2.336925953535606]
Test error averaged over all models Test RMSE: 14.148440843478621 [Test MAE: 8.06922728035217]
FINISHED at Mon Dec 19 03:16:56 CET 2022
Epoch 00685: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00164: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00105: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00060: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 3.0561637918565503 [MAE: 2.314613526084278]
Test error minimum for model run no. 10:  14.31022729290584 [MAE: 8.125377017469054]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  0.8
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  500
n_test =  500
Train error averaged over all models Train RMSE:  3.6254973074671684 [Train MAE: 2.554316772475431]
Test error averaged over all models Test RMSE: 15.118947206511072 [Test MAE: 8.43941968328735]
FINISHED at Mon Dec 19 03:27:49 CET 2022
