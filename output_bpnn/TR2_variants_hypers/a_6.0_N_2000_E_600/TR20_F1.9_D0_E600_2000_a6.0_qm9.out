STARTING AT Sat Dec 24 16:24:04 CET 2022
CUDA is available:  False
Random seed: 1000
7 18
Reading dataset
Shuffling and extracting from dataset (length: 10000)
Shuffling and extraction done
Calculating composition features
Composition features done
Calculating composition features
Composition features done
Creating datasets and dataloaders
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
nfeat: 406
Epoch 00405: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00069: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00270: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00063: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00060: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00056: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00159: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 6.505756644097303 [MAE: 5.077034555408442]
Test error minimum for model run no. 4:  9.310085377189653 [MAE: 6.2233567051419865]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 6.970709260109364 [MAE: 5.354790221779292]
Test error minimum for model run no. 1:  10.07565941343545 [MAE: 6.477031253825249]
Epoch 00467: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00356: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00116: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00140: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00067: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 6.28250220016125 [MAE: 4.978434615484744]
Test error minimum for model run no. 5:  8.66847696702364 [MAE: 6.0845453819283115]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 6.683154726127883 [MAE: 5.187402642490841]
Test error minimum for model run no. 2:  8.766856513789984 [MAE: 6.161241826461023]
Epoch 00409: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00396: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00120: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00178: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00125: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00058: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 6.225847594524356 [MAE: 4.893930868674629]
Test error minimum for model run no. 6:  8.706069716595756 [MAE: 6.014131655407946]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 6.419748045534485 [MAE: 5.012439306566164]
Test error minimum for model run no. 3:  8.626595955689647 [MAE: 6.068360135296364]
Epoch 00349: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00463: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00058: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00105: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00069: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00067: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 6.603121308048617 [MAE: 5.148630904066166]
Test error minimum for model run no. 4:  8.602716695501567 [MAE: 6.096465935537073]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 6.218801976281676 [MAE: 4.891357324267526]
Test error minimum for model run no. 7:  8.818574757597224 [MAE: 6.019772379699364]
Epoch 00455: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00476: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00067: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00256: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00064: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00189: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 6.307087102175703 [MAE: 4.996099352725706]
Test error minimum for model run no. 8:  8.694161133948013 [MAE: 6.126580029767458]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 6.112586142867515 [MAE: 4.819361626675787]
Test error minimum for model run no. 5:  8.456239991790447 [MAE: 5.952791263871298]
Epoch 00329: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00141: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00066: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00441: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00092: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00106: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 6.487015056142636 [MAE: 5.074067752199225]
Test error minimum for model run no. 9:  9.618919704806473 [MAE: 6.286162456066061]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 6.295129915005718 [MAE: 4.9489914745268235]
Test error minimum for model run no. 6:  8.402106886716115 [MAE: 6.009267608460925]
Epoch 00431: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00463: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00328: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00091: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 6.2595737912079805 [MAE: 4.947804636212591]
Test error minimum for model run no. 7:  8.45850354244145 [MAE: 6.059893896143912]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 6.294977544296516 [MAE: 4.9282027295979205]
Test error minimum for model run no. 10:  8.71643479892188 [MAE: 6.0801107130033145]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  1.9
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  2000
n_test =  2000
Train error averaged over all models Train RMSE:  6.361236580937113 [Train MAE: 4.984717627013113]
Test error averaged over all models Test RMSE: 8.916197326505536 [Test MAE: 6.114575853362458]
FINISHED at Sat Dec 24 22:20:01 CET 2022
Epoch 00527: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00103: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00083: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00089: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 5.991384153837461 [MAE: 4.715084698259502]
Test error minimum for model run no. 8:  8.80588589294935 [MAE: 6.053885517390661]
Epoch 00419: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00064: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00094: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00105: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 6.318156649851193 [MAE: 4.942956025465347]
Test error minimum for model run no. 9:  8.86403230142689 [MAE: 6.160511631562537]
Epoch 00387: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00112: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00077: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 6.4095837652295025 [MAE: 5.002154373823445]
Test error minimum for model run no. 10:  8.61445832840241 [MAE: 6.122850034911792]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  1.9
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  2000
n_test =  2000
Train error averaged over all models Train RMSE:  6.40631477578197 [Train MAE: 5.0079615909865955]
Test error averaged over all models Test RMSE: 8.76730555221433 [Test MAE: 6.1162299103460835]
FINISHED at Sun Dec 25 00:48:36 CET 2022
