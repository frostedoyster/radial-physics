STARTING AT Sat Dec 24 16:24:34 CET 2022
CUDA is available:  False
Random seed: 1000
7 18
Reading dataset
Shuffling and extracting from dataset (length: 10000)
Shuffling and extraction done
Calculating composition features
Composition features done
Calculating composition features
Composition features done
Creating datasets and dataloaders
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
Epoch 00353: reducing learning rate of group 0 to 1.0000e-04.
1900
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
nfeat: 406
Epoch 00119: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00072: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00069: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00062: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00231: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 7.031271162023346 [MAE: 5.462166852007346]
Test error minimum for model run no. 4:  9.666725616331407 [MAE: 6.591495470591707]
Epoch 00449: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00375: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00105: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00263: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00056: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00058: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00125: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 7.043814369915595 [MAE: 5.48812885453036]
Test error minimum for model run no. 5:  9.573966882132572 [MAE: 6.5332563255582645]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 7.25051494408774 [MAE: 5.590703478768107]
Test error minimum for model run no. 1:  10.591551507234533 [MAE: 6.638597752116554]
Epoch 00222: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00370: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00069: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00210: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00092: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00178: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00107: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00071: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00105: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 7.039412923124268 [MAE: 5.463011676085787]
Test error minimum for model run no. 6:  9.391687655639414 [MAE: 6.54280044111046]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 7.604427140906252 [MAE: 5.790051511419925]
Test error minimum for model run no. 2:  10.87345265261202 [MAE: 6.8597255555061185]
Epoch 00364: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00099: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00322: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00143: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00063: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00215: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00098: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00059: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 7.043711640200286 [MAE: 5.478940559300759]
Test error minimum for model run no. 7:  9.46816767014949 [MAE: 6.498379244086423]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 7.011828124394381 [MAE: 5.434353987896104]
Test error minimum for model run no. 3:  9.656541001828387 [MAE: 6.552446309265904]
Epoch 00335: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00195: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00383: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00158: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00060: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00074: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00089: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00062: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 6.962526557625313 [MAE: 5.413900612318105]
Test error minimum for model run no. 8:  9.473407843445615 [MAE: 6.476525980318042]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 6.930857558465116 [MAE: 5.4153979791755855]
Test error minimum for model run no. 4:  9.812485855340055 [MAE: 6.57087594587634]
Epoch 00314: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00437: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00099: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00093: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00465: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00098: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00132: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00063: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 6.736599657773626 [MAE: 5.270609454512494]
Test error minimum for model run no. 5:  9.385659314597058 [MAE: 6.49158842125255]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 6.827781509089463 [MAE: 5.2993239428448025]
Test error minimum for model run no. 9:  9.4852124987319 [MAE: 6.380923335363589]
Epoch 00420: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00065: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00357: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00117: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00092: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00146: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00062: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00279: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00056: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 6.848931614916838 [MAE: 5.34987131734295]
Test error minimum for model run no. 6:  9.520575429334103 [MAE: 6.506858536033052]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 7.188720991469994 [MAE: 5.576499035405422]
Test error minimum for model run no. 10:  9.788568648692477 [MAE: 6.639224688845245]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  2.1
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  2000
n_test =  2000
Train error averaged over all models Train RMSE:  6.907545849128428 [Train MAE: 5.3830174532384705]
Test error averaged over all models Test RMSE: 9.643147612921597 [Test MAE: 6.523336913256455]
FINISHED at Sat Dec 24 22:15:46 CET 2022
Epoch 00254: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00232: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00231: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00125: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 7.356787799112844 [MAE: 5.656410152433167]
Test error minimum for model run no. 7:  9.757209344473795 [MAE: 6.619819138025696]
Epoch 00306: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00264: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00080: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 6.995615977132373 [MAE: 5.437585222940344]
Test error minimum for model run no. 8:  9.684619956586866 [MAE: 6.49513633208107]
Epoch 00389: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00105: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00109: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00115: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00073: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 6.843017219302482 [MAE: 5.353125246846767]
Test error minimum for model run no. 9:  9.59712150321604 [MAE: 6.525116835862197]
Epoch 00259: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00067: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 7.618328583275375 [MAE: 5.841528090840004]
Test error minimum for model run no. 10:  9.893475106571447 [MAE: 6.787321750929131]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  2.1
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  2000
n_test =  2000
Train error averaged over all models Train RMSE:  7.119690861936702 [Train MAE: 5.513963644217545]
Test error averaged over all models Test RMSE: 9.877269167179431 [Test MAE: 6.604748657694861]
FINISHED at Sun Dec 25 01:24:38 CET 2022
