STARTING AT Mon Dec 19 17:35:18 CET 2022
CUDA is available:  False
Random seed: 1000
7 18
Reading dataset
Shuffling and extracting from dataset (length: 10000)
Shuffling and extraction done
Calculating composition features
Composition features done
Calculating composition features
Composition features done
Creating datasets and dataloaders
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
nfeat: 406
Epoch 00298: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00074: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00282: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00067: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00132: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 5.891935835341815 [MAE: 4.5343793455053385]
Test error minimum for model run no. 4:  9.393302664435096 [MAE: 6.212550113970156]
Epoch 00071: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00273: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 5.934609280719085 [MAE: 4.568970147797914]
Test error minimum for model run no. 1:  9.770111625518192 [MAE: 6.291484168843572]
Epoch 00230: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00065: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00368: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00096: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00103: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00056: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 5.721427968600587 [MAE: 4.406618411413302]
Test error minimum for model run no. 5:  9.75763712865912 [MAE: 6.243920498589713]
Epoch 00106: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00262: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 5.503143901440885 [MAE: 4.2921882988462485]
Test error minimum for model run no. 2:  9.92453190116952 [MAE: 6.135136624904527]
Epoch 00106: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00056: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00264: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 6.154445002860722 [MAE: 4.712948512901449]
Test error minimum for model run no. 6:  9.814787680701034 [MAE: 6.35194610533053]
Epoch 00154: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00061: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00148: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00308: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 5.819249351102094 [MAE: 4.478499956375741]
Test error minimum for model run no. 3:  9.57791406456986 [MAE: 6.213969464012088]
Epoch 00102: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00078: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 5.860033985034729 [MAE: 4.512955720885942]
Test error minimum for model run no. 7:  9.496561303784425 [MAE: 6.281127632664073]
Epoch 00354: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00061: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00094: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00340: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 5.644065624070141 [MAE: 4.366635173286867]
Test error minimum for model run no. 4:  9.523118552499506 [MAE: 6.171441413940294]
Epoch 00131: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00203: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00056: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00296: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 5.622194512438818 [MAE: 4.362531132947624]
Test error minimum for model run no. 8:  9.560892576455519 [MAE: 6.151689968443275]
Epoch 00222: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00058: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00060: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00101: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 5.613851652102526 [MAE: 4.369858895474638]
Test error minimum for model run no. 5:  9.744866329795363 [MAE: 6.181357881057261]
Epoch 00501: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00080: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00265: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00116: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 5.091839480874516 [MAE: 3.9989453641326]
Test error minimum for model run no. 9:  9.033125181249762 [MAE: 5.898474099516097]
Epoch 00078: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 6.051447961500123 [MAE: 4.618404466604894]
Test error minimum for model run no. 6:  9.767306588099293 [MAE: 6.2850403102660675]
Epoch 00303: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00085: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00059: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00394: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 5.7815954305659725 [MAE: 4.455452060709239]
Test error minimum for model run no. 10:  9.779397918196652 [MAE: 6.256829358141126]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  1.4
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  2000
n_test =  2000
Train error averaged over all models Train RMSE:  5.784172810595939 [Train MAE: 4.457490562570401]
Test error averaged over all models Test RMSE: 9.606989224865709 [Test MAE: 6.228881500860603]
FINISHED at Mon Dec 19 22:45:21 CET 2022
Epoch 00086: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00080: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 5.429630982143435 [MAE: 4.2290125595783294]
Test error minimum for model run no. 7:  9.511964925841978 [MAE: 6.063868234494079]
Epoch 00464: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00066: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00065: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00074: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 5.119072467965872 [MAE: 3.9767879242290727]
Test error minimum for model run no. 8:  9.146666471080428 [MAE: 5.823762539454507]
Epoch 00263: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00215: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00058: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 5.753818875494386 [MAE: 4.454655439368467]
Test error minimum for model run no. 9:  9.812197581414578 [MAE: 6.222033937297631]
Epoch 00346: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00158: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00612: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00142: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 5.708520911759166 [MAE: 4.431014480461284]
Test error minimum for model run no. 10:  9.344032508469706 [MAE: 6.171967715289732]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  1.4
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  2000
n_test =  2000
Train error averaged over all models Train RMSE:  5.657741100829772 [Train MAE: 4.378602734202346]
Test error averaged over all models Test RMSE: 9.612271054845843 [Test MAE: 6.156006228955976]
FINISHED at Tue Dec 20 02:00:58 CET 2022
