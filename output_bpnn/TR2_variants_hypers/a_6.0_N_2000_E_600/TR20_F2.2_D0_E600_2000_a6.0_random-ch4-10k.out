STARTING AT Sun Dec 18 09:50:13 CET 2022
CUDA is available:  False
Random seed: 1000
7 18
Reading dataset
Shuffling and extracting from dataset (length: 10000)
Shuffling and extraction done
Calculating composition features
Composition features done
Calculating composition features
Composition features done
Creating datasets and dataloaders
0
100
200
300
400
500
600
Epoch 00093: reducing learning rate of group 0 to 1.0000e-08.
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
0
100
200
300
400
500
600
700
800
900
1000
1100
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
1200
1300
1400
1500
1600
1700
1800
1900
nfeat: 406
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 7.552693261357851 [MAE: 5.836497889910657]
Test error minimum for model run no. 1:  9.933667560223792 [MAE: 6.741604019029708]
Epoch 00305: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00309: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00189: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00311: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00089: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00102: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00056: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00094: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00068: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 7.424113990730729 [MAE: 5.750199520859217]
Test error minimum for model run no. 2:  9.74361282421103 [MAE: 6.671732283386827]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 7.2971758900748105 [MAE: 5.670517166174871]
Test error minimum for model run no. 1:  9.69544520306432 [MAE: 6.702063650125021]
Epoch 00387: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00339: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00187: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00138: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00086: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00079: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00066: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00110: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 7.101796436113825 [MAE: 5.55868995407409]
Test error minimum for model run no. 3:  9.52867157396149 [MAE: 6.59496078978894]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 7.405019602577015 [MAE: 5.754179038995573]
Test error minimum for model run no. 2:  9.543834463812997 [MAE: 6.691719963047268]
Epoch 00361: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00217: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00450: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00630: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00214: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00497: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00122: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 7.3165571295255445 [MAE: 5.710375771015624]
Test error minimum for model run no. 3:  10.88900825504132 [MAE: 6.843264315820234]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 6.7773761613907535 [MAE: 5.305239675488123]
Test error minimum for model run no. 4:  10.477635023856216 [MAE: 6.648780494533201]
Epoch 00185: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00301: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00174: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00060: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00542: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00103: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00115: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00114: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 7.478815317489443 [MAE: 5.806898589601376]
Test error minimum for model run no. 5:  9.732674205866196 [MAE: 6.776073914956589]
Epoch 00139: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 7.658921397497327 [MAE: 5.8894203008906265]
Test error minimum for model run no. 4:  11.461892848750377 [MAE: 7.032830981911725]
Epoch 00365: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00247: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00266: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00075: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00062: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00211: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00078: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00209: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 7.046663661637245 [MAE: 5.489322890456748]
Test error minimum for model run no. 6:  9.588442374462664 [MAE: 6.585509482489955]
Epoch 00053: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00279: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 7.572254927453847 [MAE: 5.8302315832344735]
Test error minimum for model run no. 5:  9.850457270313383 [MAE: 6.761805892541143]
Epoch 00126: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00295: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00514: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00313: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00109: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00105: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00218: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00092: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00100: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 7.564714080751694 [MAE: 5.84910022761581]
Test error minimum for model run no. 7:  9.897926325916911 [MAE: 6.739065770326975]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 7.315385054714868 [MAE: 5.683299499462148]
Test error minimum for model run no. 6:  9.78840189100679 [MAE: 6.645996692201619]
Epoch 00432: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00244: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00133: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00461: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 6.919805888129164 [MAE: 5.432641123589149]
Test error minimum for model run no. 8:  9.416090062813492 [MAE: 6.577825709243186]
Epoch 00101: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00182: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00386: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00126: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 7.352195567197412 [MAE: 5.702105695545056]
Test error minimum for model run no. 7:  9.701248823240249 [MAE: 6.674723255329432]
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00296: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 7.271707877392731 [MAE: 5.696745909399602]
Test error minimum for model run no. 9:  9.741850731684309 [MAE: 6.6982233390145876]
Epoch 00080: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00234: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00235: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00243: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 7.609920599116334 [MAE: 5.879635833098402]
Test error minimum for model run no. 8:  9.740565752863892 [MAE: 6.804317152469391]
Epoch 00459: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00497: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00237: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00125: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00095: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00072: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00069: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 7.668067202163939 [MAE: 5.896528038181187]
Test error minimum for model run no. 10:  10.035020765175453 [MAE: 6.784485929707202]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  2.2
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  2000
n_test =  2000
Train error averaged over all models Train RMSE:  7.2805753877157375 [Train MAE: 5.6621863819175955]
Test error averaged over all models Test RMSE: 9.809559144817154 [Test MAE: 6.681826173247717]
FINISHED at Sun Dec 18 18:53:54 CET 2022
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 6.748743737665309 [MAE: 5.302026765163644]
Test error minimum for model run no. 9:  10.223496984633444 [MAE: 6.70949964046583]
Epoch 00531: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00231: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00085: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00104: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 6.4614295864872835 [MAE: 5.093013228608621]
Test error minimum for model run no. 10:  10.161193703421443 [MAE: 6.663051620072671]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  2.2
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  2000
n_test =  2000
Train error averaged over all models Train RMSE:  7.273760349230976 [Train MAE: 5.651480488218905]
Test error averaged over all models Test RMSE: 10.105554519614822 [Test MAE: 6.752927316398434]
FINISHED at Sun Dec 18 20:05:42 CET 2022
