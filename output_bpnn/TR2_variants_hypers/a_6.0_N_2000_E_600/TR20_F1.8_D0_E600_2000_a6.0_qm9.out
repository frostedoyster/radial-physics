STARTING AT Sat Dec 24 16:23:34 CET 2022
CUDA is available:  False
Random seed: 1000
7 18
Reading dataset
Shuffling and extracting from dataset (length: 10000)
Shuffling and extraction done
Calculating composition features
Composition features done
Calculating composition features
Composition features done
Creating datasets and dataloaders
0
100
200
300
400
500
600
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
1900
0
100
200
300
400
500
600
700
800
900
1000
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
1100
1200
1300
1400
1500
1600
1700
1800
1900
nfeat: 406
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 6.800996610903193 [MAE: 5.206811559688058]
Test error minimum for model run no. 4:  8.999173684036952 [MAE: 6.181625378018504]
Epoch 00291: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00077: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00148: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00579: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00056: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00230: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 7.041415381772379 [MAE: 5.337135895792304]
Test error minimum for model run no. 1:  8.880772496969257 [MAE: 6.177488676228295]
Epoch 00067: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00073: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 5.616250599725307 [MAE: 4.433361133887554]
Test error minimum for model run no. 5:  8.267550293612501 [MAE: 5.794288142715513]
Epoch 00455: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00524: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00694: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00065: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00087: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00115: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00160: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 5.923373757416859 [MAE: 4.687339247231685]
Test error minimum for model run no. 2:  8.389755039635999 [MAE: 5.890013198941005]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 5.674907299653054 [MAE: 4.474850776010911]
Test error minimum for model run no. 6:  8.29640332099578 [MAE: 5.849692202992124]
Epoch 00448: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00419: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00238: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00058: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00065: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 6.296600224874196 [MAE: 4.908975390713794]
Test error minimum for model run no. 7:  8.992046426652212 [MAE: 6.0597277231801385]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 6.005739006458142 [MAE: 4.7057352604606715]
Test error minimum for model run no. 3:  8.730124922011976 [MAE: 5.893462992780543]
Epoch 00509: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00078: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00088: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00649: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00065: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00060: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00065: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00111: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 5.883091755108826 [MAE: 4.616133691518292]
Test error minimum for model run no. 8:  8.379088558578449 [MAE: 5.886404325952734]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 5.55935685186467 [MAE: 4.384158142492194]
Test error minimum for model run no. 4:  7.95282418963944 [MAE: 5.708918954831658]
Epoch 00434: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00063: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00063: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00627: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 6.2602229463655625 [MAE: 4.9120391400282815]
Test error minimum for model run no. 9:  8.54057464915081 [MAE: 6.00781278394286]
Epoch 00054: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00401: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 5.669760974196505 [MAE: 4.459477172834575]
Test error minimum for model run no. 5:  8.35959500124059 [MAE: 5.7953243373540815]
Epoch 00066: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00088: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00063: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00112: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00349: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 6.357123065856652 [MAE: 4.955927703758765]
Test error minimum for model run no. 10:  8.633842090195193 [MAE: 6.059311117365951]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  1.8
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  2000
n_test =  2000
Train error averaged over all models Train RMSE:  6.114562855476199 [Train MAE: 4.7749527043243445]
Test error averaged over all models Test RMSE: 8.575840073474206 [Test MAE: 5.967592586137318]
FINISHED at Sat Dec 24 21:56:22 CET 2022
Epoch 00403: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00156: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 6.444049697576479 [MAE: 5.014514195560831]
Test error minimum for model run no. 6:  8.783828490429624 [MAE: 6.111601097467047]
Epoch 00359: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00080: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00092: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 6.486721443301392 [MAE: 5.040824327573679]
Test error minimum for model run no. 7:  8.66425670355186 [MAE: 6.079006845400025]
Epoch 00538: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00096: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 5.745955816724944 [MAE: 4.532184539561634]
Test error minimum for model run no. 8:  8.179400710122051 [MAE: 5.819908934381458]
Epoch 00335: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00060: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00059: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00064: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 6.533922977383929 [MAE: 5.065565715474094]
Test error minimum for model run no. 9:  8.861306366777942 [MAE: 6.1174453206328225]
Epoch 00429: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00668: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00104: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 5.837084303963665 [MAE: 4.574462156312243]
Test error minimum for model run no. 10:  8.274824354316463 [MAE: 5.741914546466509]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  1.8
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  2000
n_test =  2000
Train error averaged over all models Train RMSE:  6.124738021065896 [Train MAE: 4.780139665329391]
Test error averaged over all models Test RMSE: 8.50766882746952 [Test MAE: 5.933508490448345]
FINISHED at Sun Dec 25 02:10:34 CET 2022
