STARTING AT Sat Dec 24 16:22:04 CET 2022
CUDA is available:  False
Random seed: 1000
7 18
Reading dataset
Shuffling and extracting from dataset (length: 10000)
Shuffling and extraction done
Calculating composition features
Composition features done
Calculating composition features
Composition features done
Creating datasets and dataloaders
0
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
100
200
300
400
500
600
700
800
900
1000
1100
1200
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
1300
1400
1500
1600
1700
1800
1900
0
100
200
300
400
500
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
1800
1900
nfeat: 406
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 5.044940530583734 [MAE: 3.9951682240119157]
Test error minimum for model run no. 4:  8.104028181094728 [MAE: 5.621191832816688]
Epoch 00274: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00094: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00442: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00064: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00170: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00090: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 6.307618016513616 [MAE: 4.862443206892866]
Test error minimum for model run no. 5:  9.049007603912447 [MAE: 6.033248228609609]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 5.670551863713662 [MAE: 4.4405751969568685]
Test error minimum for model run no. 1:  8.562189918388018 [MAE: 5.823973119013337]
Epoch 00459: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00457: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00058: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00093: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00067: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00063: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00073: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 5.647784744036394 [MAE: 4.392118239762153]
Test error minimum for model run no. 6:  8.522110217117667 [MAE: 5.760525845569309]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 5.360119263986693 [MAE: 4.212598718361967]
Test error minimum for model run no. 2:  8.722547855617636 [MAE: 5.788591257635597]
Epoch 00412: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00062: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00495: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00064: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00063: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00069: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 5.717957118507403 [MAE: 4.449871174860289]
Test error minimum for model run no. 7:  8.583201182893337 [MAE: 5.772976051633801]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 5.39723889422647 [MAE: 4.226927650382267]
Test error minimum for model run no. 3:  8.581989954154686 [MAE: 5.757812499646003]
Epoch 00481: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00371: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00089: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00060: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00085: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 5.539700137899959 [MAE: 4.343508485200726]
Test error minimum for model run no. 8:  8.806054685272038 [MAE: 5.8209661454758885]
Epoch 00315: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-05.
Epoch 01461: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00163: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00946: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00105: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00131: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00072: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 5.75774647183087 [MAE: 4.468868526798875]
Test error minimum for model run no. 4:  8.7358045005713 [MAE: 5.810443212024965]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 6.047684996181576 [MAE: 4.668926230204317]
Test error minimum for model run no. 9:  8.991675208701796 [MAE: 5.897289543299344]
Epoch 00451: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00589: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00078: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00069: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00078: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00108: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00072: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00082: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00071: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 5.6904635145318325 [MAE: 4.428213643035128]
Test error minimum for model run no. 10:  8.496149412510656 [MAE: 5.79090711571106]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  1.6
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  2000
n_test =  2000
Train error averaged over all models Train RMSE:  5.617801875948874 [Train MAE: 4.385606609415323]
Test error averaged over all models Test RMSE: 8.569597664263362 [Test MAE: 5.783786626593594]
FINISHED at Sat Dec 24 22:06:12 CET 2022
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 5.228267394255208 [MAE: 4.097458779880107]
Test error minimum for model run no. 5:  8.283358286176002 [MAE: 5.717512670183281]
Epoch 00479: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00061: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00091: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 5.554312503573067 [MAE: 4.356716952975019]
Test error minimum for model run no. 6:  8.281524787944576 [MAE: 5.699073824080581]
Epoch 00299: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00070: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00066: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00084: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 6.260409690585914 [MAE: 4.800726752176646]
Test error minimum for model run no. 7:  8.902224569254647 [MAE: 5.997138732689758]
Epoch 00473: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00066: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00074: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 5.5296558525483395 [MAE: 4.330161049643952]
Test error minimum for model run no. 8:  8.615132693038943 [MAE: 5.801029503899138]
Epoch 00345: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 6.074473062914928 [MAE: 4.698581761534567]
Test error minimum for model run no. 9:  8.89034635302727 [MAE: 5.9519376194798745]
Epoch 00462: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 5.411734766964446 [MAE: 4.234301480124178]
Test error minimum for model run no. 10:  8.356046532014531 [MAE: 5.7121990224615935]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  1.6
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  2000
n_test =  2000
Train error averaged over all models Train RMSE:  5.6244509764599595 [Train MAE: 4.386691686883445]
Test error averaged over all models Test RMSE: 8.593116545018761 [Test MAE: 5.805971146111412]
FINISHED at Sun Dec 25 02:05:02 CET 2022
