STARTING AT Sat Dec 24 16:24:04 CET 2022
CUDA is available:  False
Random seed: 1000
7 18
Reading dataset
Shuffling and extracting from dataset (length: 10000)
Shuffling and extraction done
Calculating composition features
Composition features done
Calculating composition features
Composition features done
Creating datasets and dataloaders
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
nfeat: 406
Epoch 00381: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00146: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00143: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00335: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00143: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 6.550435263868591 [MAE: 5.13038519917053]
Test error minimum for model run no. 4:  9.391227007586664 [MAE: 6.335571680866464]
Epoch 00221: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00365: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 6.86811872652545 [MAE: 5.345503083949033]
Test error minimum for model run no. 1:  9.375914544293154 [MAE: 6.352088914217129]
Epoch 00096: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00063: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00301: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 6.6609409625493505 [MAE: 5.20054238550055]
Test error minimum for model run no. 5:  9.11877926501334 [MAE: 6.320010023603488]
Epoch 00492: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00458: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00091: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00071: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00066: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00092: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 6.5915741247419275 [MAE: 5.115847543225554]
Test error minimum for model run no. 2:  9.042392450832418 [MAE: 6.195077408137179]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 6.466298627251983 [MAE: 5.073481511373599]
Test error minimum for model run no. 6:  9.221568877496857 [MAE: 6.3562573770687925]
Epoch 00414: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00341: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00117: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00056: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00104: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 6.501633836453028 [MAE: 5.092995928146657]
Test error minimum for model run no. 3:  9.825871311087349 [MAE: 6.431764316376851]
Epoch 00820: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00075: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00467: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 6.916634723114193 [MAE: 5.379100289178135]
Test error minimum for model run no. 7:  9.001591738364787 [MAE: 6.321799996354724]
Epoch 00277: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00068: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00357: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 6.303545401241349 [MAE: 4.972056210195622]
Test error minimum for model run no. 4:  8.545943396202954 [MAE: 6.060221660729277]
Epoch 00194: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00095: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00272: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 6.885217337361941 [MAE: 5.367702137805909]
Test error minimum for model run no. 8:  9.198505963625765 [MAE: 6.410048800483558]
Epoch 00535: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00094: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00590: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00161: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00078: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00071: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00090: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00068: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 6.672448176108112 [MAE: 5.202369104847795]
Test error minimum for model run no. 5:  9.829003025472854 [MAE: 6.342516472099595]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 6.280483879098186 [MAE: 4.973245660261632]
Test error minimum for model run no. 9:  8.887426587488756 [MAE: 6.2273279701496795]
Epoch 00312: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00123: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00560: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00071: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00139: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00609: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00056: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00171: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00091: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00117: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 6.986275367194193 [MAE: 5.386682761536043]
Test error minimum for model run no. 6:  9.384281536897758 [MAE: 6.39185362704226]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 5.975835039173755 [MAE: 4.734608471179643]
Test error minimum for model run no. 10:  9.334775266326753 [MAE: 6.17170455595961]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  2.0
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  2000
n_test =  2000
Train error averaged over all models Train RMSE:  6.5777415112444 [Train MAE: 5.149120687191674]
Test error averaged over all models Test RMSE: 9.155425133479628 [Test MAE: 6.298441537181371]
FINISHED at Sat Dec 24 22:57:02 CET 2022
Epoch 00323: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00270: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00071: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00080: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 6.844471446583669 [MAE: 5.2949293085875055]
Test error minimum for model run no. 7:  9.355790854501775 [MAE: 6.289436093976444]
Epoch 00286: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00303: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00107: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00181: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00139: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 6.747446243057595 [MAE: 5.248314468559333]
Test error minimum for model run no. 8:  10.253966260329548 [MAE: 6.459501376476815]
Epoch 00511: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00060: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 6.31832462025442 [MAE: 4.977772775894618]
Test error minimum for model run no. 9:  8.821883720362152 [MAE: 6.240278803750883]
Epoch 00404: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00134: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00131: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00156: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 6.554975838820325 [MAE: 5.138166472885506]
Test error minimum for model run no. 10:  9.825973321609103 [MAE: 6.431771943783471]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  2.0
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  2000
n_test =  2000
Train error averaged over all models Train RMSE:  6.638881378098008 [Train MAE: 5.177463765782767]
Test error averaged over all models Test RMSE: 9.426102042158906 [Test MAE: 6.31945106165899]
FINISHED at Sun Dec 25 02:39:11 CET 2022
