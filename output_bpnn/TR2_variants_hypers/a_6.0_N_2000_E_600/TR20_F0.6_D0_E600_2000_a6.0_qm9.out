STARTING AT Sat Dec 24 14:17:30 CET 2022
CUDA is available:  False
Random seed: 1000
7 18
Reading dataset
Shuffling and extracting from dataset (length: 10000)
Shuffling and extraction done
Calculating composition features
Composition features done
Calculating composition features
Composition features done
Creating datasets and dataloaders
0
100
200
300
Epoch 00307: reducing learning rate of group 0 to 1.0000e-04.
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
Epoch 00056: reducing learning rate of group 0 to 1.0000e-05.
1700
1800
1900
0
100
200
300
400
500
600
700
800
900
1000
Epoch 00060: reducing learning rate of group 0 to 1.0000e-06.
1100
1200
1300
1400
1500
1600
1700
1800
1900
nfeat: 406
Epoch 00083: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 3.7258765143540056 [MAE: 2.7844713300918205]
Test error minimum for model run no. 4:  8.830450149654784 [MAE: 5.299933913759589]
Epoch 00320: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00078: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00219: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00062: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00085: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00059: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 3.6433941204713047 [MAE: 2.716818264437465]
Test error minimum for model run no. 1:  8.954448897082118 [MAE: 5.3548044043520004]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 4.391120440428226 [MAE: 3.1270599806003365]
Test error minimum for model run no. 5:  9.145136217160836 [MAE: 5.447545848019313]
Epoch 00350: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00072: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00345: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00058: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00059: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00077: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 3.557930804930714 [MAE: 2.676607148087203]
Test error minimum for model run no. 2:  8.591166552098818 [MAE: 5.187960879093943]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 3.5759593209771956 [MAE: 2.6955715914410505]
Test error minimum for model run no. 6:  9.056526899411491 [MAE: 5.225904319903264]
Epoch 00346: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00068: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00294: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00085: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00075: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00127: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00070: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 3.6256167381211495 [MAE: 2.7520191418877205]
Test error minimum for model run no. 3:  8.855439969645158 [MAE: 5.384337801752313]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 3.822701209117732 [MAE: 2.837474896007888]
Test error minimum for model run no. 7:  9.020484048359537 [MAE: 5.2501945207116085]
Epoch 00281: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00254: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00070: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 3.9364555907101226 [MAE: 2.891822074965938]
Test error minimum for model run no. 4:  8.935995475055387 [MAE: 5.209978095218066]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 4.274432562374541 [MAE: 3.0645796307950577]
Test error minimum for model run no. 8:  8.877146681719443 [MAE: 5.364000381147351]
Epoch 00286: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00311: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00060: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00087: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00123: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00063: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00072: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 3.84366716806178 [MAE: 2.8062074807686486]
Test error minimum for model run no. 5:  9.10461766507775 [MAE: 5.319419084400432]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 3.803260468490692 [MAE: 2.8109582161741513]
Test error minimum for model run no. 9:  9.025572643243763 [MAE: 5.387597685667137]
Epoch 00330: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00338: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00113: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00075: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00116: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00121: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 3.5780017971492777 [MAE: 2.6949866347294256]
Test error minimum for model run no. 6:  8.925557828277839 [MAE: 5.266910940601726]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 3.5847037565870425 [MAE: 2.694965345677553]
Test error minimum for model run no. 10:  8.767462992107212 [MAE: 5.284269409109452]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  0.6
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  2000
n_test =  2000
Train error averaged over all models Train RMSE:  3.8805536205066327 [Train MAE: 2.861685904168209]
Test error averaged over all models Test RMSE: 8.951805895148569 [Test MAE: 5.316812428258136]
FINISHED at Sat Dec 24 18:49:41 CET 2022
Epoch 00301: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00069: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 3.7579129532423114 [MAE: 2.7949658067800986]
Test error minimum for model run no. 7:  8.902979815737433 [MAE: 5.331672321948136]
Epoch 00351: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00085: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 3.463042293191684 [MAE: 2.62104083394816]
Test error minimum for model run no. 8:  8.79892011763259 [MAE: 5.232019027830847]
Epoch 00295: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00088: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00059: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 3.7710695635081675 [MAE: 2.83158251103282]
Test error minimum for model run no. 9:  9.021674965928531 [MAE: 5.28733352644445]
Epoch 00337: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00060: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00065: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 3.568472601228994 [MAE: 2.6760703232799083]
Test error minimum for model run no. 10:  8.951436172508478 [MAE: 5.270352096796678]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  0.6
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  2000
n_test =  2000
Train error averaged over all models Train RMSE:  3.6745563630615505 [Train MAE: 2.746212021991739]
Test error averaged over all models Test RMSE: 8.90422374590441 [Test MAE: 5.284478817843859]
FINISHED at Sat Dec 24 21:29:04 CET 2022
