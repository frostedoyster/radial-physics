STARTING AT Sat Dec 24 05:49:50 CET 2022
CUDA is available:  False
Random seed: 1000
7 18
Reading dataset
Shuffling and extracting from dataset (length: 10000)
Shuffling and extraction done
Calculating composition features
Composition features done
Calculating composition features
Composition features done
Creating datasets and dataloaders
0
100
200
300
400
500
600
700
800
900
0
Epoch 00129: reducing learning rate of group 0 to 1.0000e-06.
100
200
300
400
500
600
Epoch 00055: reducing learning rate of group 0 to 1.0000e-07.
700
800
900
nfeat: 406
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 6.7541632311108915 [MAE: 5.329017247662246]
Test error minimum for model run no. 1:  10.674148282323001 [MAE: 7.108033226638953]
Epoch 00492: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00441: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00064: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00088: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 7.5675305656196326 [MAE: 5.984047546601887]
Test error minimum for model run no. 2:  11.481606247727356 [MAE: 7.482420184320926]
Epoch 00438: reducing learning rate of group 0 to 1.0000e-04.
Epoch 01290: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00128: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00456: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00060: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00165: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00075: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00108: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 6.942860734280147 [MAE: 5.477134232063849]
Test error minimum for model run no. 3:  10.795287550913752 [MAE: 7.071593218819456]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 6.486742613797121 [MAE: 5.100167267741637]
Test error minimum for model run no. 1:  10.573597912823573 [MAE: 6.929860650839852]
Epoch 00478: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00478: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00056: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00080: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 7.361066073335758 [MAE: 5.853463888572424]
Test error minimum for model run no. 2:  11.226495924771273 [MAE: 7.4028257729303055]
Epoch 00894: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00163: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00088: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00608: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00139: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 6.487239362099996 [MAE: 5.131090661439862]
Test error minimum for model run no. 4:  10.595237738825386 [MAE: 6.995804649636109]
Epoch 00068: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 6.7735679320842745 [MAE: 5.3758093295108]
Test error minimum for model run no. 3:  10.861340713904324 [MAE: 7.1356026164181365]
Epoch 00405: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00286: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00569: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00268: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00635: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00102: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00096: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 6.791165396575839 [MAE: 5.363166622589702]
Test error minimum for model run no. 4:  10.617527502801629 [MAE: 7.07785356330358]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 7.182426837757332 [MAE: 5.712612081872546]
Test error minimum for model run no. 5:  11.025199204774788 [MAE: 7.159345694224827]
Epoch 00512: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00493: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00157: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00259: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00584: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00099: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00099: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 7.034651805971953 [MAE: 5.575905814477188]
Test error minimum for model run no. 6:  10.94075061351418 [MAE: 7.185950914638945]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 6.820131829997581 [MAE: 5.377813152790215]
Test error minimum for model run no. 5:  10.82380361241516 [MAE: 7.07924835900027]
Epoch 00373: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00096: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00438: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00088: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00172: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00109: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00059: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 7.68441214639165 [MAE: 6.047933753170968]
Test error minimum for model run no. 7:  11.308268547072371 [MAE: 7.444462793548984]
Epoch 00189: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 7.493494457023498 [MAE: 5.939802856163539]
Test error minimum for model run no. 6:  11.50524263909812 [MAE: 7.487731715154213]
Epoch 00446: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00089: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00377: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00135: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00079: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 7.45861491230596 [MAE: 5.939309488305527]
Test error minimum for model run no. 8:  11.187175599378046 [MAE: 7.372407721116658]
Epoch 00662: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00058: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00492: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00063: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00060: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 7.057959550357831 [MAE: 5.602289795792964]
Test error minimum for model run no. 7:  10.95187980328011 [MAE: 7.169640279636614]
Epoch 00166: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 7.4046057690811855 [MAE: 5.853536143985628]
Test error minimum for model run no. 9:  11.3901505373649 [MAE: 7.418370770232831]
Epoch 00514: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00081: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00154: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00084: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00563: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 7.144917135250669 [MAE: 5.66884022603284]
Test error minimum for model run no. 8:  11.147570588209241 [MAE: 7.264256385231926]
Epoch 00205: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00110: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00492: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 6.853725107146063 [MAE: 5.429043902303176]
Test error minimum for model run no. 10:  10.731087714312364 [MAE: 7.164673369786009]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  2.2
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  1000
n_test =  1000
Train error averaged over all models Train RMSE:  7.1370230471764815 [Train MAE: 5.6479630871882875]
Test error averaged over all models Test RMSE: 11.012891203620615 [Test MAE: 7.240306254296371]
FINISHED at Sat Dec 24 10:53:43 CET 2022
Epoch 00202: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00056: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 7.086563129123697 [MAE: 5.592743089817022]
Test error minimum for model run no. 9:  11.125116074943394 [MAE: 7.188849264065972]
Epoch 00545: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00099: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00429: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00123: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 6.9907791540799415 [MAE: 5.522685988130935]
Test error minimum for model run no. 10:  11.313650914297748 [MAE: 7.2189598463250135]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  2.2
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  1000
n_test =  1000
Train error averaged over all models Train RMSE:  7.000638727162621 [Train MAE: 5.539678221714208]
Test error averaged over all models Test RMSE: 11.014622568654456 [Test MAE: 7.195482845290587]
FINISHED at Sat Dec 24 11:45:52 CET 2022
