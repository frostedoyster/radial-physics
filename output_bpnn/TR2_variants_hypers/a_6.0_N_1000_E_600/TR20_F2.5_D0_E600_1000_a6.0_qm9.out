STARTING AT Sat Dec 24 05:58:50 CET 2022
CUDA is available:  False
Random seed: 1000
7 18
Reading dataset
Shuffling and extracting from dataset (length: 10000)
Shuffling and extraction done
Calculating composition features
Composition features done
Calculating composition features
Composition features done
Creating datasets and dataloaders
0
100
200
300
400
500
600
700
800
900
0
100
200
300
400
500
600
700
800
900
nfeat: 406
Epoch 01063: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00097: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00514: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00084: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 8.526667195097232 [MAE: 6.609676896795753]
Test error minimum for model run no. 1:  11.801446679630708 [MAE: 8.059046648667861]
Epoch 00329: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00488: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00579: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00121: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00091: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00094: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00196: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 8.185254339427594 [MAE: 6.400118957348774]
Test error minimum for model run no. 1:  11.240268255373175 [MAE: 7.748632773889317]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 8.721157505251812 [MAE: 6.764634443293936]
Test error minimum for model run no. 2:  11.380783041286909 [MAE: 7.947485408548313]
Epoch 00445: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00168: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00652: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00248: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00189: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00062: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00191: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00133: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00073: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 8.927349130711013 [MAE: 6.913995095089114]
Test error minimum for model run no. 2:  11.741745135097105 [MAE: 8.105591449577933]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 8.000102709675623 [MAE: 6.251769720357371]
Test error minimum for model run no. 3:  11.203323805351388 [MAE: 7.685878573602286]
Epoch 00445: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00440: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00135: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00614: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00112: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 8.291920409028807 [MAE: 6.484555047775998]
Test error minimum for model run no. 3:  11.05317524369885 [MAE: 7.626782651539684]
Epoch 00420: reducing learning rate of group 0 to 1.0000e-04.
Epoch 01435: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00255: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00068: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00111: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00070: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00160: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 8.608579975290908 [MAE: 6.72542350574923]
Test error minimum for model run no. 4:  11.508512130720817 [MAE: 7.943773235034188]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 8.80178631486761 [MAE: 6.849504710953245]
Test error minimum for model run no. 4:  11.437225235287421 [MAE: 8.029035658211644]
Epoch 00471: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00450: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00170: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00363: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00073: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00093: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 8.616544156576916 [MAE: 6.697100882191767]
Test error minimum for model run no. 5:  11.60885521616012 [MAE: 8.001628809166519]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 8.365609802748004 [MAE: 6.528938193448097]
Test error minimum for model run no. 5:  11.45202720690939 [MAE: 7.885613415965745]
Epoch 00511: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00119: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00868: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00085: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 8.830377827895639 [MAE: 6.891499479146607]
Test error minimum for model run no. 6:  11.663600724972726 [MAE: 8.140630119604216]
Epoch 00090: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 7.5509250201165505 [MAE: 5.860699005108181]
Test error minimum for model run no. 6:  11.368996921726298 [MAE: 7.798952856445101]
Epoch 00491: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00459: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00341: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00081: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00080: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00069: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00156: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00064: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 8.521413715953503 [MAE: 6.617213839427865]
Test error minimum for model run no. 7:  11.340151484850713 [MAE: 7.896097827929338]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 8.854970433109223 [MAE: 6.916724210960112]
Test error minimum for model run no. 7:  11.844724429114894 [MAE: 8.17902539474486]
Epoch 00528: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00618: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00380: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00176: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00109: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00184: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00071: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00062: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00149: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 8.10914975150914 [MAE: 6.311211556073034]
Test error minimum for model run no. 8:  11.355510120475342 [MAE: 7.8384809798245945]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 8.099715175340037 [MAE: 6.334863219656612]
Test error minimum for model run no. 8:  11.310310389933008 [MAE: 7.74911957935744]
Epoch 00443: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00367: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00347: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00101: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 9.035534354952375 [MAE: 6.998971119704435]
Test error minimum for model run no. 9:  12.040184026712971 [MAE: 8.19533869685246]
Epoch 01429: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00666: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00091: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00068: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00099: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00111: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00075: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 7.635649535382967 [MAE: 6.008331782956213]
Test error minimum for model run no. 9:  10.609879492099713 [MAE: 7.228880303966568]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 8.244753262747095 [MAE: 6.4404941657118515]
Test error minimum for model run no. 10:  11.448413704202457 [MAE: 7.8547004333434405]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  2.5
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  1000
n_test =  1000
Train error averaged over all models Train RMSE:  8.460875259687722 [Train MAE: 6.589702641450009]
Test error averaged over all models Test RMSE: 11.509389855730628 [Test MAE: 7.928880830312839]
FINISHED at Sat Dec 24 11:45:10 CET 2022
Epoch 00466: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00130: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00135: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00192: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00101: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 8.677813741957983 [MAE: 6.756436667442098]
Test error minimum for model run no. 10:  11.532403394248778 [MAE: 8.001573743250786]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  2.5
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  1000
n_test =  1000
Train error averaged over all models Train RMSE:  8.399652176076282 [Train MAE: 6.54651360846902]
Test error averaged over all models Test RMSE: 11.384763808054647 [Test MAE: 7.862746025639389]
FINISHED at Sat Dec 24 12:13:54 CET 2022
