STARTING AT Sat Dec 24 05:48:50 CET 2022
CUDA is available:  False
Random seed: 1000
7 18
Reading dataset
Shuffling and extracting from dataset (length: 10000)
Shuffling and extraction done
Calculating composition features
Composition features done
Calculating composition features
Composition features done
Creating datasets and dataloaders
0
100
200
300
400
500
600
700
800
900
0
100
200
300
400
500
600
700
800
900
nfeat: 406
Epoch 00424: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00277: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 6.8069860159065465 [MAE: 5.323220680097667]
Test error minimum for model run no. 1:  11.359581507401874 [MAE: 7.252242783756392]
Epoch 00908: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00066: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00059: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00422: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00147: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 5.801961952293518 [MAE: 4.57342949232468]
Test error minimum for model run no. 1:  10.712499174905735 [MAE: 6.804785775859348]
Epoch 00163: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 7.4346265297210135 [MAE: 5.85493687236517]
Test error minimum for model run no. 2:  11.69307020039371 [MAE: 7.471303193061811]
Epoch 00698: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00138: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00075: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00111: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00649: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00146: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 6.2175621085135715 [MAE: 4.865373445375082]
Test error minimum for model run no. 2:  10.959255108836022 [MAE: 6.828041412783367]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 6.524632613863717 [MAE: 5.121875643420373]
Test error minimum for model run no. 3:  11.21967050506467 [MAE: 7.176153227250572]
Epoch 00552: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00615: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00346: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00109: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00125: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00061: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00060: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 6.474866304760206 [MAE: 5.105823886636601]
Test error minimum for model run no. 3:  11.292703420331316 [MAE: 7.200364958326498]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 6.5464766549074165 [MAE: 5.156172756565515]
Test error minimum for model run no. 4:  10.974684420576716 [MAE: 7.154524554781976]
Epoch 00508: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00162: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00710: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00146: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 6.900745059528721 [MAE: 5.426199966610616]
Test error minimum for model run no. 4:  11.540898507930567 [MAE: 7.445400568806997]
Epoch 00459: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00111: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00058: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00063: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 6.0854009465862955 [MAE: 4.7719394648332765]
Test error minimum for model run no. 5:  10.235570920400585 [MAE: 6.688682319507828]
Epoch 00711: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00121: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00110: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00674: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 6.405464426274787 [MAE: 5.018988933373865]
Test error minimum for model run no. 5:  10.920765694924324 [MAE: 6.9876130598726665]
Epoch 00124: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00058: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 6.483092390702377 [MAE: 5.08103686302133]
Test error minimum for model run no. 6:  11.48388662081768 [MAE: 7.330192566353548]
Epoch 00520: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00072: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00142: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00080: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00480: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 6.826463686746165 [MAE: 5.348790362431872]
Test error minimum for model run no. 6:  11.208995061176125 [MAE: 7.2419694183880745]
Epoch 00192: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00126: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 6.927826294998817 [MAE: 5.442922206240564]
Test error minimum for model run no. 7:  11.716710240996168 [MAE: 7.460045581895353]
Epoch 00918: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00107: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00089: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00079: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00783: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00139: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 5.681166529920943 [MAE: 4.444442966842303]
Test error minimum for model run no. 7:  10.240141049327505 [MAE: 6.674449402812716]
Epoch 00240: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00089: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00444: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 5.9271099490337225 [MAE: 4.629438038230667]
Test error minimum for model run no. 8:  10.929304669742269 [MAE: 7.122080704798436]
Epoch 00159: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00128: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 7.280443463425738 [MAE: 5.710790492395241]
Test error minimum for model run no. 8:  11.48091597173575 [MAE: 7.375491312166133]
Epoch 00555: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00124: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00086: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00423: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 6.885084597158797 [MAE: 5.415686664331892]
Test error minimum for model run no. 9:  11.78991302634862 [MAE: 7.354680700211609]
Epoch 00195: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00175: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00089: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00071: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00522: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 7.112621548629353 [MAE: 5.608723324761578]
Test error minimum for model run no. 9:  11.7913772128695 [MAE: 7.533192675662992]
Epoch 00432: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00104: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00109: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 6.857026956556975 [MAE: 5.397605009166597]
Test error minimum for model run no. 10:  11.354860523990371 [MAE: 7.269859680615581]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  2.0
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  1000
n_test =  1000
Train error averaged over all models Train RMSE:  6.647826294943568 [Train MAE: 5.219483419827306]
Test error averaged over all models Test RMSE: 11.275725263573264 [Test MAE: 7.22797653122331]
FINISHED at Sat Dec 24 11:09:57 CET 2022
Epoch 00918: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00134: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 5.8658719391900105 [MAE: 4.588845058277133]
Test error minimum for model run no. 10:  10.152089606404926 [MAE: 6.541984516157283]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  2.0
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  1000
n_test =  1000
Train error averaged over all models Train RMSE:  6.456716701928302 [Train MAE: 5.069140792902897]
Test error averaged over all models Test RMSE: 11.029964080844177 [Test MAE: 7.063329310083607]
FINISHED at Sat Dec 24 11:24:00 CET 2022
