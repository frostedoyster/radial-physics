STARTING AT Mon Dec 19 06:22:33 CET 2022
CUDA is available:  False
Random seed: 1000
7 18
Reading dataset
Shuffling and extracting from dataset (length: 10000)
Shuffling and extraction done
Calculating composition features
Composition features done
Calculating composition features
Composition features done
Creating datasets and dataloaders
0
100
200
Epoch 00080: reducing learning rate of group 0 to 1.0000e-06.
300
400
500
600
700
800
Epoch 00054: reducing learning rate of group 0 to 1.0000e-07.
900
0
100
200
300
400
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
500
600
700
800
900
nfeat: 406
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 5.246257232600535 [MAE: 4.09678544633496]
Test error minimum for model run no. 1:  10.58837755144049 [MAE: 6.53403695773125]
Epoch 00661: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00065: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00110: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00607: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00113: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 5.6255408179226505 [MAE: 4.4256819784061285]
Test error minimum for model run no. 1:  11.067087677217794 [MAE: 6.712467210743024]
Epoch 00654: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00096: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00058: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00514: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 5.385353023187601 [MAE: 4.156340427230194]
Test error minimum for model run no. 2:  10.61476367111193 [MAE: 6.497887449619279]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 6.2513052721435685 [MAE: 4.833539611990032]
Test error minimum for model run no. 2:  11.554444730077984 [MAE: 7.065484994465497]
Epoch 00702: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00495: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00056: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00113: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00068: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00064: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 5.389127151871264 [MAE: 4.221227050038954]
Test error minimum for model run no. 3:  10.801209689429673 [MAE: 6.67959835198052]
Epoch 00610: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00451: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00608: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00058: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00106: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00071: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00067: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 5.557702120775611 [MAE: 4.314936681102158]
Test error minimum for model run no. 3:  10.633283876657142 [MAE: 6.508755322371758]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 5.683703168173929 [MAE: 4.419029272956594]
Test error minimum for model run no. 4:  11.394509819279202 [MAE: 6.874504814440364]
Epoch 00588: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00078: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00067: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00802: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00059: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 5.935001123891269 [MAE: 4.60900354510264]
Test error minimum for model run no. 4:  11.027113677434386 [MAE: 6.84767736758596]
Epoch 00398: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00096: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 5.465490548596871 [MAE: 4.290453663667268]
Test error minimum for model run no. 5:  11.056841481656624 [MAE: 6.762320090530204]
Epoch 00643: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00532: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00313: reducing learning rate of group 0 to 1.0000e-05.
Epoch 01060: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00344: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00099: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00157: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 5.6727888891732725 [MAE: 4.422687182523738]
Test error minimum for model run no. 6:  10.881234149229863 [MAE: 6.682011368168481]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 5.353077361102832 [MAE: 4.110635986029609]
Test error minimum for model run no. 5:  10.808380182570323 [MAE: 6.436772567874203]
Epoch 00648: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00640: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00201: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00214: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00065: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 5.442688987542935 [MAE: 4.224629971327724]
Test error minimum for model run no. 7:  10.494792806544996 [MAE: 6.398816984914512]
Epoch 00657: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00143: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00178: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00080: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 5.59724587594337 [MAE: 4.350005184800171]
Test error minimum for model run no. 8:  11.127223313606189 [MAE: 6.763882580571359]
Epoch 02237: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00099: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00523: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00064: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 5.465166621624355 [MAE: 4.221492285314893]
Test error minimum for model run no. 6:  10.724999737982829 [MAE: 6.552154774050395]
Epoch 00356: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00079: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00143: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 6.000422517822273 [MAE: 4.6397066783422565]
Test error minimum for model run no. 9:  10.88870107383249 [MAE: 6.869897384402676]
Epoch 00652: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00089: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00458: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00711: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00063: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 5.716828761007861 [MAE: 4.4559633809347785]
Test error minimum for model run no. 7:  11.010125950636157 [MAE: 6.769606912526415]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 5.3853578051622035 [MAE: 4.180956516201633]
Test error minimum for model run no. 10:  10.776592586691839 [MAE: 6.578823890559579]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  1.8
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  1000
n_test =  1000
Train error averaged over all models Train RMSE:  5.526843520007426 [Train MAE: 4.300182139342349]
Test error averaged over all models Test RMSE: 10.862424614282329 [Test MAE: 6.664177987291822]
FINISHED at Mon Dec 19 11:55:59 CET 2022
Epoch 00396: reducing learning rate of group 0 to 1.0000e-04.
Epoch 01294: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00253: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00075: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00117: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 5.815559000664682 [MAE: 4.46731130769864]
Test error minimum for model run no. 8:  11.233969821906618 [MAE: 6.782048222158916]
Epoch 00584: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00289: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00140: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00068: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 5.6020566975787025 [MAE: 4.331363694090135]
Test error minimum for model run no. 9:  10.675179021521268 [MAE: 6.655206874175443]
Epoch 00557: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00246: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00239: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00233: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 5.836326508721649 [MAE: 4.530555740951033]
Test error minimum for model run no. 10:  11.303886757399319 [MAE: 6.802735589105124]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  1.8
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  1000
n_test =  1000
Train error averaged over all models Train RMSE:  5.715856428543319 [Train MAE: 4.430048421162004]
Test error averaged over all models Test RMSE: 11.003847143340383 [Test MAE: 6.713290983505672]
FINISHED at Mon Dec 19 14:07:03 CET 2022
