STARTING AT Sat Dec 24 05:33:20 CET 2022
CUDA is available:  False
Random seed: 1000
7 18
Reading dataset
Shuffling and extracting from dataset (length: 10000)
Shuffling and extraction done
Calculating composition features
Composition features done
Calculating composition features
Composition features done
Creating datasets and dataloaders
0
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
100
200
300
400
500
600
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
700
800
900
0
100
200
300
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 2.9872659131528865 [MAE: 2.1860889490833637]
Test error minimum for model run no. 1:  11.676472662973637 [MAE: 6.2944552175570285]
400
500
600
700
800
900
nfeat: 406
Epoch 00306: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00385: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00069: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00130: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00065: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00123: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00091: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 3.527617347220224 [MAE: 2.558480262802835]
Test error minimum for model run no. 2:  12.041570361036317 [MAE: 6.630842909530157]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 3.9297290853159987 [MAE: 2.8603064994508256]
Test error minimum for model run no. 1:  12.3594646179373 [MAE: 6.650184994281021]
Epoch 00427: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00374: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00086: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00084: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00062: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00072: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00226: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 3.1409787512066614 [MAE: 2.3336887607551637]
Test error minimum for model run no. 3:  12.103697759790451 [MAE: 6.455337881674214]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 3.4010854096511305 [MAE: 2.5463085394687863]
Test error minimum for model run no. 2:  11.79668553560647 [MAE: 6.3315365868865845]
Epoch 00336: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00109: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00101: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00059: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00430: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00071: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00089: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 3.358694290187199 [MAE: 2.505774806401118]
Test error minimum for model run no. 4:  12.16902577833401 [MAE: 6.5283219289502785]
Epoch 00095: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 3.0459586535139564 [MAE: 2.3289846444916815]
Test error minimum for model run no. 3:  11.169238021000798 [MAE: 6.015474642843154]
Epoch 00368: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00165: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00078: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00400: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00102: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00089: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00072: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 3.236816759974066 [MAE: 2.399750105105323]
Test error minimum for model run no. 5:  11.865426688331585 [MAE: 6.418478554623774]
Epoch 00084: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 3.413276175115663 [MAE: 2.596896015440027]
Test error minimum for model run no. 4:  10.768976706223881 [MAE: 5.864054279405803]
Epoch 00327: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00073: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00102: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00340: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00074: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00143: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00280: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 3.7066238761409833 [MAE: 2.786213280022342]
Test error minimum for model run no. 6:  11.922243689715557 [MAE: 6.3401763621657485]
Epoch 00081: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 3.4126462564803903 [MAE: 2.5485037215382356]
Test error minimum for model run no. 5:  12.074281234223504 [MAE: 6.432055607418409]
Epoch 00373: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00218: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00459: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 3.224227202058121 [MAE: 2.3668494645831855]
Test error minimum for model run no. 7:  13.24505287316713 [MAE: 6.77415097935692]
Epoch 00229: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00267: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00339: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00058: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00184: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00074: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00069: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00122: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 3.394847020394926 [MAE: 2.5381960140319437]
Test error minimum for model run no. 8:  11.936340365792926 [MAE: 6.432755666819596]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 2.901213674167418 [MAE: 2.1790810032202406]
Test error minimum for model run no. 6:  11.788952620936685 [MAE: 6.429527469551651]
Epoch 00334: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00356: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00079: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00252: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00320: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00107: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00155: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00059: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 3.478111054810748 [MAE: 2.602581997338991]
Test error minimum for model run no. 9:  11.961810709693177 [MAE: 6.4547513947442]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 3.2222954322168853 [MAE: 2.423942195940939]
Test error minimum for model run no. 7:  11.818772557177722 [MAE: 6.409690963090452]
Epoch 00342: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00377: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00076: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 3.398812772029634 [MAE: 2.51168645838753]
Test error minimum for model run no. 10:  12.31818436494683 [MAE: 6.667673643134329]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  0.6
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  1000
n_test =  1000
Train error averaged over all models Train RMSE:  3.3453994987175455 [Train MAE: 2.4789310098511796]
Test error averaged over all models Test RMSE: 12.123982525378164 [Test MAE: 6.499694453855625]
FINISHED at Sat Dec 24 09:10:20 CET 2022
Epoch 00350: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00061: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 3.27792033034714 [MAE: 2.449129522516613]
Test error minimum for model run no. 8:  12.035532183593917 [MAE: 6.363566239823106]
Epoch 00399: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00058: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00058: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 3.076050310490393 [MAE: 2.3074233576949865]
Test error minimum for model run no. 9:  11.903700713998559 [MAE: 6.359114637657068]
Epoch 00403: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00129: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 3.1782177619016405 [MAE: 2.390175618308733]
Test error minimum for model run no. 10:  11.831372952046332 [MAE: 6.39502619810331]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  0.6
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  1000
n_test =  1000
Train error averaged over all models Train RMSE:  3.2858393089200617 [Train MAE: 2.4630751118071066]
Test error averaged over all models Test RMSE: 11.754697714274517 [Test MAE: 6.3250231619060555]
FINISHED at Sat Dec 24 10:03:49 CET 2022
