STARTING AT Sun Dec 18 00:16:35 CET 2022
CUDA is available:  False
Random seed: 1000
7 18
Reading dataset
Shuffling and extracting from dataset (length: 10000)
Shuffling and extraction done
Calculating composition features
Composition features done
Calculating composition features
Composition features done
Creating datasets and dataloaders
0
100
200
300
400
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 3.509914802607322 [MAE: 2.632747505185994]
Test error minimum for model run no. 1:  11.843062265535515 [MAE: 6.465915861068328]
500
600
700
800
900
0
100
200
300
400
500
600
700
800
900
nfeat: 406
Epoch 00418: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00317: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00135: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00176: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00124: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00062: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 3.3986589635153477 [MAE: 2.535120610501706]
Test error minimum for model run no. 2:  11.933428289208521 [MAE: 6.405918086361566]
Epoch 00406: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00092: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00085: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 3.1606792323177015 [MAE: 2.3667847210863266]
Test error minimum for model run no. 3:  12.058843095546923 [MAE: 6.4897852643240235]
Epoch 01500: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00353: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00403: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00224: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00113: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 3.5564110578932535 [MAE: 2.6541326100293556]
Test error minimum for model run no. 1:  11.705559946543456 [MAE: 6.394012747607996]
Epoch 00113: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 3.348193100465723 [MAE: 2.497012360642073]
Test error minimum for model run no. 4:  11.850030093044246 [MAE: 6.422563226846474]
Epoch 00436: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00079: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00056: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00062: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00360: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00082: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00120: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00106: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 3.164372761132972 [MAE: 2.385287566765087]
Test error minimum for model run no. 2:  11.962675550117108 [MAE: 6.5140761424032405]
Epoch 00169: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00352: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 3.4479451561632066 [MAE: 2.567296488806103]
Test error minimum for model run no. 5:  11.917344158488456 [MAE: 6.327299581710596]
Epoch 00100: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00058: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00064: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00362: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 3.2861547029250837 [MAE: 2.5269213322628263]
Test error minimum for model run no. 3:  11.217777826914425 [MAE: 5.909506838608552]
Epoch 00129: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00080: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00127: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00321: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00084: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 3.2229844464370787 [MAE: 2.41969034257277]
Test error minimum for model run no. 6:  11.993178626470096 [MAE: 6.4634648313097145]
Epoch 00081: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 3.6822766530233455 [MAE: 2.648055082657742]
Test error minimum for model run no. 4:  12.424885414819283 [MAE: 6.717879058188374]
Epoch 00341: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00106: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00376: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 3.6096280667130327 [MAE: 2.712434226502194]
Test error minimum for model run no. 7:  11.999719804015385 [MAE: 6.372330026921636]
Epoch 00299: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00297: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00100: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00269: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00077: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00100: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00088: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 3.1053780286588437 [MAE: 2.3144247470114565]
Test error minimum for model run no. 5:  13.294302203973729 [MAE: 6.570787109339777]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 3.4642472873115997 [MAE: 2.5945107849431226]
Test error minimum for model run no. 8:  12.15657892993143 [MAE: 6.518152369471503]
Epoch 00319: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00074: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00434: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00082: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00189: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00068: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 3.8132008493390552 [MAE: 2.793924459308433]
Test error minimum for model run no. 6:  11.904415747643668 [MAE: 6.576259680477774]
Epoch 00342: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00364: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00110: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00071: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 2.9477755710972757 [MAE: 2.205791839222196]
Test error minimum for model run no. 9:  11.911581188200861 [MAE: 6.350095819029228]
Epoch 00117: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00088: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 3.5128542787630797 [MAE: 2.6911039793840845]
Test error minimum for model run no. 7:  11.002809143524322 [MAE: 6.0218155218146405]
Epoch 00373: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00145: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00453: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00076: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00393: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00285: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 2.919727547610295 [MAE: 2.1833962389985078]
Test error minimum for model run no. 8:  11.764461847102218 [MAE: 6.3642235141617025]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 3.141083842280415 [MAE: 2.364675722321658]
Test error minimum for model run no. 10:  12.15392884523821 [MAE: 6.535169333287147]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  0.6
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  1000
n_test =  1000
Train error averaged over all models Train RMSE:  3.32511104689087 [Train MAE: 2.4896064601784142]
Test error averaged over all models Test RMSE: 11.981769529567964 [Test MAE: 6.435069440033021]
FINISHED at Sun Dec 18 04:30:03 CET 2022
Epoch 00340: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00248: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00101: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 3.2871878329597117 [MAE: 2.454865415343984]
Test error minimum for model run no. 9:  11.95534860637583 [MAE: 6.4082491240836585]
Epoch 00368: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00119: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00088: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00087: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 3.2844955698814298 [MAE: 2.455466631267003]
Test error minimum for model run no. 10:  12.092518369805147 [MAE: 6.523157113359621]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  0.6
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  1000
n_test =  1000
Train error averaged over all models Train RMSE:  3.361205928218707 [Train MAE: 2.510757806302848]
Test error averaged over all models Test RMSE: 11.932475465681918 [Test MAE: 6.399996685004533]
FINISHED at Sun Dec 18 05:13:38 CET 2022
