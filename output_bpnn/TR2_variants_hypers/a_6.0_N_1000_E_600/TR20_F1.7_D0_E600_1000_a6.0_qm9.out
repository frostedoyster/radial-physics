STARTING AT Sat Dec 24 05:43:50 CET 2022
CUDA is available:  False
Random seed: 1000
7 18
Reading dataset
Shuffling and extracting from dataset (length: 10000)
Shuffling and extraction done
Calculating composition features
Composition features done
Calculating composition features
Composition features done
Creating datasets and dataloaders
0
100
200
300
400
500
600
700
800
900
0
100
200
300
400
500
600
700
800
900
nfeat: 406
Epoch 00516: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 5.596314713637275 [MAE: 4.388365823839338]
Test error minimum for model run no. 1:  11.040223859266781 [MAE: 6.8668499500078966]
Epoch 00487: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00125: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00087: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00400: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00130: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00245: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00073: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 5.933403721536211 [MAE: 4.635363540046428]
Test error minimum for model run no. 1:  11.24747044005681 [MAE: 6.979597342273979]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 6.135026042793168 [MAE: 4.784417782869312]
Test error minimum for model run no. 2:  11.272042496760982 [MAE: 7.110949531986641]
Epoch 00581: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00517: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00225: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00086: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00092: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00498: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00444: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 5.326900697246077 [MAE: 4.194435383227159]
Test error minimum for model run no. 2:  11.163974428363636 [MAE: 6.804287841137913]
Epoch 00347: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 5.675161051236073 [MAE: 4.484957455841717]
Test error minimum for model run no. 3:  10.866408943643494 [MAE: 6.796478971426135]
Epoch 00523: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00126: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00135: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00598: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00136: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00067: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00103: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00119: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 5.406635186367937 [MAE: 4.240918277326699]
Test error minimum for model run no. 3:  11.19066779156541 [MAE: 6.765295762311028]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 5.536236164815036 [MAE: 4.344250761946079]
Test error minimum for model run no. 4:  11.100246213323416 [MAE: 6.804130265938718]
Epoch 00523: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00418: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00213: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00058: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00106: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00402: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00063: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 5.622446909296359 [MAE: 4.398717520222528]
Test error minimum for model run no. 4:  11.176212166775745 [MAE: 6.808220070572653]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 5.763634448226642 [MAE: 4.516886155764625]
Test error minimum for model run no. 5:  11.037153138667394 [MAE: 6.794353284184168]
Epoch 00509: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00070: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00612: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00084: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00176: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 5.718456369499423 [MAE: 4.49319989973717]
Test error minimum for model run no. 6:  11.044094383757395 [MAE: 6.901319362518698]
Epoch 00226: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 5.439403836482902 [MAE: 4.277979231572745]
Test error minimum for model run no. 5:  11.019169022466855 [MAE: 6.815456744597826]
Epoch 00517: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00078: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00093: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00513: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00089: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 5.8501243147179665 [MAE: 4.595413215053379]
Test error minimum for model run no. 7:  11.065589448107623 [MAE: 6.870621129371695]
Epoch 00059: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00485: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00250: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00222: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00101: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00100: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 5.584170384226125 [MAE: 4.413641501658541]
Test error minimum for model run no. 8:  10.921943761906121 [MAE: 6.80749797693017]
Epoch 01667: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00076: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00501: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 5.7045113894330415 [MAE: 4.491658217184843]
Test error minimum for model run no. 6:  11.167169410797571 [MAE: 6.922718727469711]
Epoch 00062: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00116: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00058: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 5.646933182238051 [MAE: 4.443572474281626]
Test error minimum for model run no. 9:  11.12325051587721 [MAE: 6.8031617054929185]
Epoch 00506: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00197: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00449: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00118: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00096: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 5.6844749790875175 [MAE: 4.450242923609382]
Test error minimum for model run no. 7:  10.667466250494089 [MAE: 6.706238496429374]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 6.2432658413847095 [MAE: 4.8443723958170395]
Test error minimum for model run no. 10:  11.83816252225853 [MAE: 7.348724813151562]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  1.7
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  1000
n_test =  1000
Train error averaged over all models Train RMSE:  5.7749322512774475 [Train MAE: 4.5309077466808825]
Test error averaged over all models Test RMSE: 11.130911528356895 [Test MAE: 6.91040869910086]
FINISHED at Sat Dec 24 10:33:20 CET 2022
Epoch 00501: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00127: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00059: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 5.771554417947394 [MAE: 4.541439726588909]
Test error minimum for model run no. 8:  10.9487811701767 [MAE: 6.886418632443749]
Epoch 00452: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00440: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00059: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00077: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 5.642114955867686 [MAE: 4.4418240778581275]
Test error minimum for model run no. 9:  10.88810302936895 [MAE: 6.743880183732942]
Epoch 00464: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00256: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00676: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00151: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 5.599304882302847 [MAE: 4.4121050777965785]
Test error minimum for model run no. 10:  11.12843932436249 [MAE: 6.750612700027366]
E_max_2 =  600
Cutoff Radius =  6.0
Selected Radial Transform =  20.0
factor =  1.7
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  1000
n_test =  1000
Train error averaged over all models Train RMSE:  5.613075097556797 [Train MAE: 4.40846839754334]
Test error averaged over all models Test RMSE: 11.059745303442826 [Test MAE: 6.8182726500996536]
FINISHED at Sat Dec 24 12:17:36 CET 2022
