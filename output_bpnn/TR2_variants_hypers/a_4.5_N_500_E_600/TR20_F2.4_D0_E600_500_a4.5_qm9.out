STARTING AT Tue Dec 20 14:05:01 CET 2022
CUDA is available:  False
Random seed: 1000
7 18
Reading dataset
Shuffling and extracting from dataset (length: 10000)
Shuffling and extraction done
Calculating composition features
Composition features done
Calculating composition features
Composition features done
Creating datasets and dataloaders
0
100
200
300
400
0
100
200
300
400
nfeat: 406
Epoch 00511: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00232: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00151: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 8.876560507689785 [MAE: 6.207875897592434]
Test error minimum for model run no. 1:  14.52248940321859 [MAE: 9.020608681606788]
Epoch 00780: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00219: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00626: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00072: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00078: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 9.397321985900744 [MAE: 6.426089050297171]
Test error minimum for model run no. 2:  13.024386204062498 [MAE: 9.322235215689412]
Epoch 00420: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00531: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00126: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 10.056178498506517 [MAE: 6.485026158945817]
Test error minimum for model run no. 3:  14.455170809177744 [MAE: 9.224037745926342]
Epoch 00391: reducing learning rate of group 0 to 1.0000e-04.
Epoch 02785: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00110: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00056: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 7.557314353792999 [MAE: 5.662823986799984]
Test error minimum for model run no. 1:  12.098324590120443 [MAE: 8.64198917340849]
Epoch 01076: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00574: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00410: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00133: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00697: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00099: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00073: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 8.897992288879244 [MAE: 6.126996018814]
Test error minimum for model run no. 2:  14.555094476612641 [MAE: 9.02801664673538]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 9.258179102830255 [MAE: 6.138286076690845]
Test error minimum for model run no. 4:  13.751333497188535 [MAE: 8.709952100550247]
Epoch 00294: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00532: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00167: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00074: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00080: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 9.799331500211572 [MAE: 6.486887831795802]
Test error minimum for model run no. 5:  15.011994882771878 [MAE: 9.290853522047898]
Epoch 00321: reducing learning rate of group 0 to 1.0000e-04.
Epoch 01540: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00059: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00062: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00077: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 9.571894698314265 [MAE: 6.201298851099556]
Test error minimum for model run no. 3:  13.520512872011894 [MAE: 8.70770848486559]
Epoch 00292: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00178: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00150: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00077: reducing learning rate of group 0 to 1.0000e-07.
Epoch 01521: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00113: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 13.5214124550505 [MAE: 7.458998118318529]
Test error minimum for model run no. 4:  17.067219155572303 [MAE: 9.777579364717432]
Epoch 00583: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00068: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 9.797929905214911 [MAE: 6.492870330001961]
Test error minimum for model run no. 5:  14.839969205271657 [MAE: 9.522806658424448]
Epoch 01512: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00080: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00394: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 8.93039664904382 [MAE: 6.040936650933352]
Test error minimum for model run no. 6:  12.795217327051764 [MAE: 8.328559116007767]
Epoch 00288: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 10.96958607291413 [MAE: 6.725719525148418]
Test error minimum for model run no. 6:  15.500616921344175 [MAE: 9.50769416847606]
Epoch 00510: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00317: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00099: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00112: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 9.951330303124688 [MAE: 6.553998458423544]
Test error minimum for model run no. 7:  14.427352666328801 [MAE: 9.172503000716315]
Epoch 01022: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00058: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00082: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00503: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 7.241092685226848 [MAE: 5.559225092591239]
Test error minimum for model run no. 7:  11.80597564377715 [MAE: 8.646069832898805]
Epoch 00183: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00082: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00436: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 9.875959563136673 [MAE: 6.445807340098316]
Test error minimum for model run no. 8:  14.977850365702457 [MAE: 9.272148054170842]
Epoch 00174: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00505: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00102: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00729: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 10.767293042772874 [MAE: 6.7477529799626526]
Test error minimum for model run no. 8:  14.909758884758938 [MAE: 9.41707186795149]
Epoch 00280: reducing learning rate of group 0 to 1.0000e-04.
Epoch 01213: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00307: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00062: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 7.245983340044572 [MAE: 5.465376785305263]
Test error minimum for model run no. 9:  11.700490112031462 [MAE: 8.174045744196949]
Epoch 01851: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00056: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00268: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00079: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 9.169199330213223 [MAE: 5.95133616419275]
Test error minimum for model run no. 9:  12.717302192255627 [MAE: 8.442279941192643]
Epoch 00646: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00359: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00060: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00062: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 12.0916561538249 [MAE: 6.992579392259676]
Test error minimum for model run no. 10:  15.172185067377475 [MAE: 9.34424103168245]
E_max_2 =  600
Cutoff Radius =  4.5
Selected Radial Transform =  20.0
factor =  2.4
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  500
n_test =  500
Train error averaged over all models Train RMSE:  9.548289760431354 [Train MAE: 6.324286364234221]
Test error averaged over all models Test RMSE: 13.98384703349112 [Test MAE: 8.985918421259502]
FINISHED at Tue Dec 20 17:56:16 CET 2022
Epoch 01594: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00296: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 9.010697368265182 [MAE: 5.9860937992293195]
Test error minimum for model run no. 10:  12.34132379900407 [MAE: 8.468023605848146]
E_max_2 =  600
Cutoff Radius =  4.5
Selected Radial Transform =  20.0
factor =  2.4
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  500
n_test =  500
Train error averaged over all models Train RMSE:  9.650441220064417 [Train MAE: 6.291311486615842]
Test error averaged over all models Test RMSE: 13.93560977407289 [Test MAE: 9.015923974451848]
FINISHED at Tue Dec 20 18:20:55 CET 2022
