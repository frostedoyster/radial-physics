STARTING AT Sun Dec 18 16:53:49 CET 2022
CUDA is available:  False
Random seed: 1000
7 18
Reading dataset
Shuffling and extracting from dataset (length: 10000)
Shuffling and extraction done
Calculating composition features
Composition features done
Calculating composition features
Composition features done
Creating datasets and dataloaders
0
100
200
300
400
500
600
700
800
900
0
100
200
300
400
500
600
700
800
900
nfeat: 406
Epoch 00740: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00095: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 5.729764293039256 [MAE: 4.505455790398832]
Test error minimum for model run no. 1:  10.393730145629162 [MAE: 6.462718454950083]
Epoch 00516: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00059: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00485: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 6.211206280041388 [MAE: 4.865044189731443]
Test error minimum for model run no. 1:  11.721225242326037 [MAE: 7.150979637439616]
Epoch 00509: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00703: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00096: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00110: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00082: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00374: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 5.737722894998275 [MAE: 4.477501503362337]
Test error minimum for model run no. 2:  10.447333153264248 [MAE: 6.590729732258608]
Epoch 00205: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00061: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00389: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 5.651732749222496 [MAE: 4.41279286532726]
Test error minimum for model run no. 2:  11.563504630580335 [MAE: 6.510721273808805]
Epoch 00069: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00087: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 6.808446399156408 [MAE: 5.299638887607544]
Test error minimum for model run no. 3:  13.906535312338928 [MAE: 7.976105136434942]
Epoch 00534: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00254: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00444: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 5.913395367184039 [MAE: 4.624644027471606]
Test error minimum for model run no. 3:  11.614914497654889 [MAE: 6.688821842684374]
Epoch 00566: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00056: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00109: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00613: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 5.9874538401788095 [MAE: 4.6495272167358594]
Test error minimum for model run no. 4:  11.96276870416595 [MAE: 7.031544988505625]
Epoch 00082: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00163: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00118: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 5.448111387978056 [MAE: 4.260080309918501]
Test error minimum for model run no. 4:  11.345687019547936 [MAE: 6.770922895464831]
Epoch 00706: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 5.3199364386991475 [MAE: 4.147194146043356]
Test error minimum for model run no. 5:  10.496132385822778 [MAE: 6.359197106757289]
Epoch 00579: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 5.954467493247753 [MAE: 4.6703040356594325]
Test error minimum for model run no. 5:  11.262493958619014 [MAE: 7.0210289753788055]
Epoch 00604: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00061: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 5.638982934895224 [MAE: 4.427828503182425]
Test error minimum for model run no. 6:  11.467944549162848 [MAE: 6.57436756267915]
Epoch 00664: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00091: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00060: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00060: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00093: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 5.421107049244199 [MAE: 4.226569527674083]
Test error minimum for model run no. 6:  10.415089708101593 [MAE: 6.730136586966648]
Epoch 00586: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00097: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 5.728209477012472 [MAE: 4.496245099923323]
Test error minimum for model run no. 7:  11.85860872983963 [MAE: 6.883488339235913]
Epoch 00685: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00229: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00489: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00113: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00159: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00307: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00173: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 5.340001723883769 [MAE: 4.193264538125963]
Test error minimum for model run no. 7:  10.863661352336194 [MAE: 6.459219417967609]
Epoch 00174: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00097: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 5.922872727603612 [MAE: 4.678217484999112]
Test error minimum for model run no. 8:  11.63538543107714 [MAE: 7.134249070040624]
Epoch 00760: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00079: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00182: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00613: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00178: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 5.216033675715505 [MAE: 4.081714123709054]
Test error minimum for model run no. 8:  10.49922378533461 [MAE: 6.556241604515004]
Epoch 00188: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00070: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00085: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 5.699357051936078 [MAE: 4.48418151876737]
Test error minimum for model run no. 9:  11.767492650404968 [MAE: 6.858506610043131]
Epoch 00601: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00056: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00062: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00112: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 5.9102020618100175 [MAE: 4.641877138736953]
Test error minimum for model run no. 9:  11.45033247077255 [MAE: 6.808347082313676]
Epoch 00868: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00149: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00519: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00205: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00097: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00071: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 4.9087693507345165 [MAE: 3.8614695226962703]
Test error minimum for model run no. 10:  10.42944961593444 [MAE: 6.50715866198041]
E_max_2 =  600
Cutoff Radius =  4.5
Selected Radial Transform =  20.0
factor =  1.9
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  1000
n_test =  1000
Train error averaged over all models Train RMSE:  5.748151540825379 [Train MAE: 4.502725967371642]
Test error averaged over all models Test RMSE: 11.436538067764008 [Test MAE: 6.837806566288577]
FINISHED at Sun Dec 18 22:17:31 CET 2022
Epoch 00772: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00093: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00114: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 5.69746923044663 [MAE: 4.487560212560085]
Test error minimum for model run no. 10:  11.410936975083459 [MAE: 6.676238861106593]
E_max_2 =  600
Cutoff Radius =  4.5
Selected Radial Transform =  20.0
factor =  1.9
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  1000
n_test =  1000
Train error averaged over all models Train RMSE:  5.676372701877385 [Train MAE: 4.446385096891438]
Test error averaged over all models Test RMSE: 11.214706964035662 [Test MAE: 6.737265817764596]
FINISHED at Sun Dec 18 22:43:10 CET 2022
