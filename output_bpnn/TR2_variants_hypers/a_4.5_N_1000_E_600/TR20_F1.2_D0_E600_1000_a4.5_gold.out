STARTING AT Sun Dec 18 16:46:22 CET 2022
CUDA is available:  False
Random seed: 1000
7 18
Reading dataset
Shuffling and extracting from dataset (length: 10000)
Shuffling and extraction done
Calculating composition features
Composition features done
Calculating composition features
Composition features done
Creating datasets and dataloaders
0
100
200
300
400
500
600
700
800
900
0
100
200
300
400
500
600
700
800
900
nfeat: 406
Epoch 00399: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00119: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 4.440507850613997 [MAE: 3.349373224971019]
Test error minimum for model run no. 1:  13.79842874201883 [MAE: 7.219416327439906]
Epoch 00551: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00401: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00319: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00065: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00124: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00137: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00074: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 4.595256327818163 [MAE: 3.5470119756213077]
Test error minimum for model run no. 2:  13.080848139229559 [MAE: 6.924011561410563]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 3.5638382349720077 [MAE: 2.7483630556294023]
Test error minimum for model run no. 1:  12.685743815226367 [MAE: 6.66648214519947]
Epoch 00458: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00540: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00236: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00085: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 3.9236726120769774 [MAE: 3.0035116068731584]
Test error minimum for model run no. 2:  12.876511322134302 [MAE: 6.72184452342883]
Epoch 00374: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00348: reducing learning rate of group 0 to 1.0000e-05.
Epoch 01360: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00058: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00078: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 3.7687895941583247 [MAE: 2.8897618123360047]
Test error minimum for model run no. 3:  13.76630086365823 [MAE: 6.9458062668294875]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 4.733181378828115 [MAE: 3.624730358986623]
Test error minimum for model run no. 3:  12.918437103491051 [MAE: 6.78912899612052]
Epoch 00457: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00480: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00106: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00084: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00087: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00278: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00056: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 4.237938633243708 [MAE: 3.2428896087409624]
Test error minimum for model run no. 4:  14.528256408641262 [MAE: 7.171070651115901]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 4.010575289703648 [MAE: 3.1010217901266564]
Test error minimum for model run no. 4:  13.464849813622793 [MAE: 6.999537565313632]
Epoch 00311: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00426: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00207: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00103: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00123: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 4.216950269070846 [MAE: 3.236314550182876]
Test error minimum for model run no. 5:  13.435718247342065 [MAE: 7.051833971597377]
Epoch 01086: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00065: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00064: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00393: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 4.116429058215469 [MAE: 3.1695523377290513]
Test error minimum for model run no. 5:  12.642932406752648 [MAE: 6.5665427361473805]
Epoch 00062: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00066: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00329: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 4.686280574142831 [MAE: 3.567539437271398]
Test error minimum for model run no. 6:  14.10577209493874 [MAE: 7.192367870551918]
Epoch 00063: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00302: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00349: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00083: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00083: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 4.777922766092442 [MAE: 3.687318122491656]
Test error minimum for model run no. 6:  14.674720028069475 [MAE: 7.287455861907988]
Epoch 00748: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00067: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00425: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 4.081343899020372 [MAE: 3.195382344307109]
Test error minimum for model run no. 7:  13.170328913206818 [MAE: 6.921976117595198]
Epoch 00398: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00060: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00056: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00073: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00380: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 4.259518037257179 [MAE: 3.1684435590621876]
Test error minimum for model run no. 7:  14.497163155285369 [MAE: 7.28025020116715]
Epoch 00457: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00085: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00823: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00063: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00082: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00058: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 4.311625662514899 [MAE: 3.3332735193548273]
Test error minimum for model run no. 8:  12.898871214856996 [MAE: 6.762216203734494]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 4.145084222747469 [MAE: 3.203337091962571]
Test error minimum for model run no. 8:  11.916045698402556 [MAE: 6.533313901413776]
Epoch 00334: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00309: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00167: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00068: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 4.7648285355424225 [MAE: 3.7057457320622857]
Test error minimum for model run no. 9:  13.239144483589932 [MAE: 6.836876912382153]
Epoch 00505: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00090: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00337: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 4.976918221464875 [MAE: 3.8295272755050727]
Test error minimum for model run no. 9:  13.426076142726096 [MAE: 6.85454101296958]
Epoch 00301: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00501: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 4.800391836197155 [MAE: 3.7418615456498237]
Test error minimum for model run no. 10:  13.11348484933252 [MAE: 6.893592927699227]
E_max_2 =  600
Cutoff Radius =  4.5
Selected Radial Transform =  20.0
factor =  1.2
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  1000
n_test =  1000
Train error averaged over all models Train RMSE:  4.407320830165376 [Train MAE: 3.383523143801913]
Test error averaged over all models Test RMSE: 13.624015029143479 [Test MAE: 6.988723964983424]
FINISHED at Sun Dec 18 21:59:29 CET 2022
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00060: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 4.030030524804224 [MAE: 3.110810352761866]
Test error minimum for model run no. 10:  14.56145919151701 [MAE: 7.391368028695546]
E_max_2 =  600
Cutoff Radius =  4.5
Selected Radial Transform =  20.0
factor =  1.2
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  1000
n_test =  1000
Train error averaged over all models Train RMSE:  4.236787522683136 [Train MAE: 3.262053786360673]
Test error averaged over all models Test RMSE: 13.25609423426078 [Test MAE: 6.912239413288586]
FINISHED at Sun Dec 18 22:10:03 CET 2022
