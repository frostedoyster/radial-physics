STARTING AT Sun Dec 18 16:40:31 CET 2022
CUDA is available:  False
Random seed: 1000
7 18
Reading dataset
Shuffling and extracting from dataset (length: 10000)
Shuffling and extraction done
Calculating composition features
Composition features done
Calculating composition features
Composition features done
Creating datasets and dataloaders
0
100
200
300
400
500
600
700
800
900
0
100
200
300
400
500
600
700
800
900
nfeat: 406
Epoch 00271: reducing learning rate of group 0 to 1.0000e-04.
Epoch 01386: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00210: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00208: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 2.8919048498186557 [MAE: 2.1632072118899663]
Test error minimum for model run no. 1:  12.493070041800143 [MAE: 6.43736583912865]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 2.480830096515772 [MAE: 1.8697599034732237]
Test error minimum for model run no. 1:  12.201841692880299 [MAE: 6.266387882836368]
Epoch 00292: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00268: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00167: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00118: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00056: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00100: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 2.7013006437849127 [MAE: 2.0639117677139667]
Test error minimum for model run no. 2:  12.335096040087992 [MAE: 6.359113846843517]
Epoch 00703: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00068: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00282: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 3.1488396242472616 [MAE: 2.3839856076343455]
Test error minimum for model run no. 2:  12.290811975099821 [MAE: 6.301097266308713]
Epoch 00118: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00090: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00137: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00331: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00061: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00067: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 2.9437216342103962 [MAE: 2.208347489053859]
Test error minimum for model run no. 3:  12.333525346786082 [MAE: 6.407616887960767]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 2.7543123979675297 [MAE: 2.0870236982024304]
Test error minimum for model run no. 3:  12.0055786831437 [MAE: 6.450129170579082]
Epoch 00353: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00282: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00088: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00096: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00251: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00085: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00148: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 2.9571866575874237 [MAE: 2.2226012028872204]
Test error minimum for model run no. 4:  12.299053556391705 [MAE: 6.29029612729614]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 2.3723016500860816 [MAE: 1.7977569585609974]
Test error minimum for model run no. 4:  12.579003379878069 [MAE: 6.509182404732037]
Epoch 00374: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00257: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00063: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00093: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00123: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00112: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00098: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 2.408193943633894 [MAE: 1.829552403017876]
Test error minimum for model run no. 5:  12.099543004674416 [MAE: 6.283482269568555]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 3.227632181235665 [MAE: 2.4741295528747247]
Test error minimum for model run no. 5:  12.26159742842329 [MAE: 6.391287065915927]
Epoch 00228: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00248: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00191: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00161: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00331: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00074: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 3.2587348216813448 [MAE: 2.4477072250629903]
Test error minimum for model run no. 6:  12.43150326740752 [MAE: 6.386264795461391]
Epoch 00102: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00140: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00322: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00093: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 2.779116655968588 [MAE: 2.0648176952058623]
Test error minimum for model run no. 6:  12.243423030357157 [MAE: 6.262069343724966]
Epoch 00198: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00119: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00103: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00414: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 2.772416984751499 [MAE: 2.0831619341019865]
Test error minimum for model run no. 7:  12.174686478922728 [MAE: 6.2729007391897]
Epoch 00053: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00262: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 2.447869107123246 [MAE: 1.8829604240040962]
Test error minimum for model run no. 7:  11.640209391705552 [MAE: 6.254079978223645]
Epoch 00259: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00402: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00243: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00094: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00292: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00201: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00058: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 2.9900424068532443 [MAE: 2.280032671810395]
Test error minimum for model run no. 8:  11.833122387799753 [MAE: 6.218126053856541]
Epoch 00529: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00096: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00274: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00080: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 2.8944622457823286 [MAE: 2.194010624298377]
Test error minimum for model run no. 8:  12.111326124720593 [MAE: 6.227587877334665]
Epoch 00061: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00321: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00065: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 3.0223407684592876 [MAE: 2.312745769057288]
Test error minimum for model run no. 9:  12.309793007111658 [MAE: 6.381270205067254]
Epoch 00161: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00310: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00215: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00150: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 2.700698218253621 [MAE: 2.0339234343361015]
Test error minimum for model run no. 9:  12.447902235373018 [MAE: 6.387940549420137]
Epoch 00140: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00116: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00065: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00248: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00109: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 2.8017126576588858 [MAE: 2.1391358052259655]
Test error minimum for model run no. 10:  11.821521750586134 [MAE: 6.284061333983952]
E_max_2 =  600
Cutoff Radius =  4.5
Selected Radial Transform =  20.0
factor =  0.5
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  1000
n_test =  1000
Train error averaged over all models Train RMSE:  2.817794255519896 [Train MAE: 2.1387045345397118]
Test error averaged over all models Test RMSE: 12.185036180453583 [Test MAE: 6.350417295943726]
FINISHED at Sun Dec 18 21:05:21 CET 2022
Epoch 00102: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00119: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 3.204752191293594 [MAE: 2.4380920129886547]
Test error minimum for model run no. 10:  12.466467760703614 [MAE: 6.413909840588386]
E_max_2 =  600
Cutoff Radius =  4.5
Selected Radial Transform =  20.0
factor =  0.5
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  1000
n_test =  1000
Train error averaged over all models Train RMSE:  2.8580427181714265 [Train MAE: 2.158981804600321]
Test error averaged over all models Test RMSE: 12.25287147793174 [Test MAE: 6.327999651858314]
FINISHED at Sun Dec 18 21:15:38 CET 2022
