STARTING AT Tue Dec 20 06:02:04 CET 2022
CUDA is available:  False
Random seed: 1000
7 18
Reading dataset
Shuffling and extracting from dataset (length: 10000)
Shuffling and extraction done
Calculating composition features
Composition features done
Calculating composition features
Composition features done
Creating datasets and dataloaders
0
100
200
300
Epoch 00615: reducing learning rate of group 0 to 1.0000e-05.
400
500
600
700
800
900
0
100
200
300
400
Epoch 00090: reducing learning rate of group 0 to 1.0000e-06.
500
600
700
800
900
nfeat: 406
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 4.731980886320953 [MAE: 3.655240794467357]
Test error minimum for model run no. 7:  11.945281792549308 [MAE: 6.763307714301741]
Epoch 00483: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00094: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00461: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00075: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00077: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00141: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 5.3903169065315995 [MAE: 4.155392444352857]
Test error minimum for model run no. 1:  12.331321810849522 [MAE: 7.08542584005401]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 5.077276753604561 [MAE: 3.9797473648795845]
Test error minimum for model run no. 8:  11.828120112487014 [MAE: 6.969552665790308]
Epoch 00583: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00432: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00059: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00074: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00078: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00086: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00210: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00169: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 4.524538504501697 [MAE: 3.536134420588022]
Test error minimum for model run no. 2:  11.836229581790226 [MAE: 6.53813026845073]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 5.266477421172755 [MAE: 4.139261100389703]
Test error minimum for model run no. 9:  11.963726945643419 [MAE: 7.0142066255514885]
Epoch 00530: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00383: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00080: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00079: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 5.569090010484283 [MAE: 4.380767794702485]
Test error minimum for model run no. 10:  12.205858033507557 [MAE: 7.144458595446303]
E_max_2 =  600
Cutoff Radius =  4.5
Selected Radial Transform =  20.0
factor =  1.6
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  1000
n_test =  1000
Train error averaged over all models Train RMSE:  5.007508808367489 [Train MAE: 3.9100326063960518]
Test error averaged over all models Test RMSE: 11.985878302778994 [Test MAE: 6.829532093665206]
FINISHED at Tue Dec 20 07:30:43 CET 2022
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 4.780982038780392 [MAE: 3.752265052461375]
Test error minimum for model run no. 3:  11.729854630319672 [MAE: 7.034044019027022]
Epoch 00396: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 5.440243813786255 [MAE: 4.278803393354247]
Test error minimum for model run no. 4:  12.334924042945827 [MAE: 7.116268583352095]
Epoch 00421: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00066: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00136: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00085: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 5.635651157814205 [MAE: 4.3780913036279605]
Test error minimum for model run no. 5:  12.221279383308017 [MAE: 7.158680540644882]
Epoch 00597: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 4.641860042218964 [MAE: 3.6119380279022004]
Test error minimum for model run no. 6:  11.68155863786177 [MAE: 6.8212089052762215]
Epoch 00391: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00447: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00066: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00112: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00072: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 5.146831214555882 [MAE: 3.9768429340207128]
Test error minimum for model run no. 7:  12.240227343757121 [MAE: 6.948762347009147]
Epoch 00440: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00065: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00098: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 5.569277032267864 [MAE: 4.288935954890522]
Test error minimum for model run no. 8:  12.231877504391077 [MAE: 7.299322268182654]
Epoch 00642: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00064: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00070: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 4.3497157819775945 [MAE: 3.3946882220631376]
Test error minimum for model run no. 9:  11.517519879363988 [MAE: 6.610885211771396]
Epoch 00433: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00086: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 5.487621175026915 [MAE: 4.30180832183808]
Test error minimum for model run no. 10:  12.393329243303265 [MAE: 7.148873500187091]
E_max_2 =  600
Cutoff Radius =  4.5
Selected Radial Transform =  20.0
factor =  1.6
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  1000
n_test =  1000
Train error averaged over all models Train RMSE:  5.096703766746137 [Train MAE: 3.9674900075099115]
Test error averaged over all models Test RMSE: 12.05181220578905 [Test MAE: 6.976160148395526]
FINISHED at Tue Dec 20 10:33:31 CET 2022
