STARTING AT Tue Dec 20 06:11:51 CET 2022
CUDA is available:  False
Random seed: 1000
7 18
Reading dataset
Shuffling and extracting from dataset (length: 10000)
Shuffling and extraction done
Calculating composition features
Composition features done
Calculating composition features
Composition features done
Creating datasets and dataloaders
0
100
200
300
400
500
600
700
800
900
0
100
200
300
400
500
600
700
800
900
nfeat: 406
Epoch 00673: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00106: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00443: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00073: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00112: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00339: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 5.987985964215149 [MAE: 4.682144359177787]
Test error minimum for model run no. 6:  10.564848421897146 [MAE: 6.7726778232028]
Epoch 00259: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00111: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00080: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00469: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00134: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 6.72968588325265 [MAE: 5.293069333207145]
Test error minimum for model run no. 1:  11.105670862767036 [MAE: 7.162908724450097]
Epoch 00054: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00079: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 6.7131952703469375 [MAE: 5.303116103106862]
Test error minimum for model run no. 7:  11.144402392160616 [MAE: 7.284246532504766]
Epoch 00377: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00629: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 01151: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00095: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00064: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00098: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00662: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 6.259101391207778 [MAE: 4.936336306278997]
Test error minimum for model run no. 2:  10.643618678629396 [MAE: 6.757043445196375]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 6.36753107270783 [MAE: 4.99147634561248]
Test error minimum for model run no. 8:  11.039240080509506 [MAE: 7.078191266927425]
Epoch 00420: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00557: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00226: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00266: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00072: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00129: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00824: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 6.373819909302956 [MAE: 5.032640794926815]
Test error minimum for model run no. 3:  10.824799644902539 [MAE: 7.000317681006286]
Epoch 00295: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00060: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00093: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00454: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 6.3899636365876775 [MAE: 5.04444390275392]
Test error minimum for model run no. 9:  10.82777360628274 [MAE: 6.971063879383427]
Epoch 00219: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00243: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00432: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00095: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 6.794591485444743 [MAE: 5.35539406660141]
Test error minimum for model run no. 4:  11.099015582496904 [MAE: 7.17263539996288]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 6.956744062876618 [MAE: 5.490043532882827]
Test error minimum for model run no. 10:  11.594041365139741 [MAE: 7.362891845171001]
E_max_2 =  600
Cutoff Radius =  4.5
Selected Radial Transform =  20.0
factor =  2.2
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  1000
n_test =  1000
Train error averaged over all models Train RMSE:  6.415421660920849 [Train MAE: 5.039764427108176]
Test error averaged over all models Test RMSE: 10.97944317412136 [Test MAE: 7.0591152268504445]
FINISHED at Tue Dec 20 09:09:45 CET 2022
Epoch 00543: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00188: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00100: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00063: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 6.533081787319645 [MAE: 5.16479353892121]
Test error minimum for model run no. 5:  10.839489194905312 [MAE: 7.064291376301405]
Epoch 00533: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00086: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00109: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 6.537478439187801 [MAE: 5.167203482188026]
Test error minimum for model run no. 6:  10.779367457198248 [MAE: 7.03136977619608]
Epoch 00548: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00132: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00123: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 6.503185395191769 [MAE: 5.157938810294048]
Test error minimum for model run no. 7:  11.065853904191608 [MAE: 7.09887577568089]
Epoch 00519: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00185: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00054: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00085: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00082: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 6.4953493959685185 [MAE: 5.117810597320365]
Test error minimum for model run no. 8:  11.072107921891675 [MAE: 7.124050448939074]
Epoch 00556: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00107: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00085: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00102: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 6.306087859968305 [MAE: 4.950112390174683]
Test error minimum for model run no. 9:  10.638104325697897 [MAE: 6.97686409947725]
Epoch 00748: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00675: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00095: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 5.6961378413312405 [MAE: 4.461503252026368]
Test error minimum for model run no. 10:  10.205716261270508 [MAE: 6.630762054400435]
E_max_2 =  600
Cutoff Radius =  4.5
Selected Radial Transform =  20.0
factor =  2.2
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  1000
n_test =  1000
Train error averaged over all models Train RMSE:  6.422851938817542 [Train MAE: 5.063680257193907]
Test error averaged over all models Test RMSE: 10.827374383395114 [Test MAE: 7.001911878161077]
FINISHED at Tue Dec 20 12:15:58 CET 2022
