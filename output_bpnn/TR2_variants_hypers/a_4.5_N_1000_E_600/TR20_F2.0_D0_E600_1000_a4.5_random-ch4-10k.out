STARTING AT Sat Dec 17 10:36:59 CET 2022
CUDA is available:  False
Random seed: 1000
7 18
Reading dataset
Shuffling and extracting from dataset (length: 10000)
Shuffling and extraction done
Calculating composition features
Composition features done
Calculating composition features
Composition features done
Creating datasets and dataloaders
0
100
200
300
400
500
600
700
800
900
Epoch 00130: reducing learning rate of group 0 to 1.0000e-06.
0
100
200
300
400
500
600
Epoch 00054: reducing learning rate of group 0 to 1.0000e-07.
700
800
900
nfeat: 406
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 4.936418478095114 [MAE: 3.859173343026537]
Test error minimum for model run no. 1:  9.918601792392801 [MAE: 6.424541540434222]
Epoch 00401: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00085: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00104: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00095: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00479: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00178: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 1: 6.840496813770682 [MAE: 5.38976521310985]
Test error minimum for model run no. 1:  11.666589364699021 [MAE: 7.3488255130797775]
Epoch 00104: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00058: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 6.491606753617953 [MAE: 5.100484599842298]
Test error minimum for model run no. 2:  11.761220733973078 [MAE: 7.372831197346585]
Epoch 00448: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00069: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00372: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00119: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00235: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00097: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 7.0541927263472175 [MAE: 5.577826334685857]
Test error minimum for model run no. 3:  11.815511860064243 [MAE: 7.390498913037961]
Epoch 01241: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00085: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 2: 6.653603248711511 [MAE: 5.257350148714008]
Test error minimum for model run no. 2:  11.566445158793666 [MAE: 7.293790345253284]
Epoch 00794: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00075: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00063: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00072: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00498: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00110: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 5.667586584451792 [MAE: 4.438874932670105]
Test error minimum for model run no. 4:  10.857234000503283 [MAE: 6.725502901590324]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 3: 6.476791799400448 [MAE: 5.087969902048995]
Test error minimum for model run no. 3:  11.61872496168754 [MAE: 7.163765739781347]
Epoch 00503: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00633: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-05.
Epoch 01226: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00159: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00958: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00195: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00152: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 5.644627018488029 [MAE: 4.427696531073072]
Test error minimum for model run no. 5:  10.826394331478172 [MAE: 6.711873004326346]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 4: 5.548742109792555 [MAE: 4.39964250656345]
Test error minimum for model run no. 4:  10.756125272027413 [MAE: 6.506548274454629]
Epoch 00447: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00456: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00094: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00072: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00186: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00090: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00179: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 6.58450392373813 [MAE: 5.206390557184417]
Test error minimum for model run no. 6:  11.632766593269347 [MAE: 7.240502541445673]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 5: 6.7239592486639 [MAE: 5.290329615510037]
Test error minimum for model run no. 5:  11.892897393251827 [MAE: 7.367141323830735]
Epoch 00522: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00112: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00477: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00132: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 6.362222379630804 [MAE: 5.030300892271916]
Test error minimum for model run no. 7:  11.752387717292482 [MAE: 7.320788120189327]
Epoch 00591: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00168: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 01264: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00073: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00177: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00090: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 6.04105692841717 [MAE: 4.736948966001793]
Test error minimum for model run no. 8:  11.394449105716701 [MAE: 7.080182381497146]
Epoch 00111: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 6: 5.66491600061478 [MAE: 4.413632504256128]
Test error minimum for model run no. 6:  11.191210965134081 [MAE: 6.900383089982602]
Epoch 00730: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00059: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00666: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00078: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00063: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 5.775758206982167 [MAE: 4.51218665611453]
Test error minimum for model run no. 9:  10.885895665657966 [MAE: 6.917648723574481]
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 7: 5.893855166378622 [MAE: 4.6443711913357495]
Test error minimum for model run no. 7:  10.890589035826922 [MAE: 6.814530889245428]
Epoch 00760: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00056: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00727: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 5.599241652473632 [MAE: 4.3801185967668275]
Test error minimum for model run no. 10:  11.046553420522947 [MAE: 7.026619116880745]
E_max_2 =  600
Cutoff Radius =  4.5
Selected Radial Transform =  20.0
factor =  2.0
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  1000
n_test =  1000
Train error averaged over all models Train RMSE:  6.0157214652242015 [Train MAE: 4.727000140963735]
Test error averaged over all models Test RMSE: 11.189101522087103 [Test MAE: 7.021098844032281]
FINISHED at Sat Dec 17 15:47:23 CET 2022
Epoch 00103: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00074: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00099: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 8: 5.716294127492655 [MAE: 4.432793919399064]
Test error minimum for model run no. 8:  11.212466267773252 [MAE: 6.94738330556034]
Epoch 00656: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00276: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00055: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00108: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00077: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 9: 5.769387354928363 [MAE: 4.521320970342777]
Test error minimum for model run no. 9:  11.113290975613396 [MAE: 7.055172958139239]
Epoch 00595: reducing learning rate of group 0 to 1.0000e-04.
Epoch 00263: reducing learning rate of group 0 to 1.0000e-05.
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch 00057: reducing learning rate of group 0 to 1.0000e-07.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-09.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-10.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-11.
Epoch 00052: reducing learning rate of group 0 to 1.0000e-12.
Very small learning rate reached: 1e-12
Train error minimum for model run no. 10: 5.891667760342002 [MAE: 4.667275901491159]
Test error minimum for model run no. 10:  11.194936741446979 [MAE: 7.015454667411129]
E_max_2 =  600
Cutoff Radius =  4.5
Selected Radial Transform =  20.0
factor =  2.0
displacement =  0.0
dataset =  datasets/random-ch4-10k.extxyz
n_train =  1000
n_test =  1000
Train error averaged over all models Train RMSE:  6.117971363009552 [Train MAE: 4.810445187277122]
Test error averaged over all models Test RMSE: 11.31032761362541 [Test MAE: 7.0412996106738515]
FINISHED at Sat Dec 17 17:07:18 CET 2022
